\documentclass[BSc, 12pt]{thesis/usydthesis}
\usepackage[margin=2.5cm]{geometry}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{enumitem}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{setspace}
\usepackage{pdflscape}
\usepackage{xcolor}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\author{Daniel Bruwel}
\title{Navigating the Pachner Graph: Algorithms for Searching and Sampling Triangulations}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% causes equations to be numbered as section.equation
\numberwithin{equation}{chapter}

% uncomment the following if you want the numbers of
% the theorems etc to appear on the left
% \swapnumbers

% I've set this up so that equations and theorems (etc)
% have a common numbering. If you don't want this change
% `equation' below to something else
\newtheorem{Definition}[equation]{Definition}
\newtheorem{Theorem}[equation]{Theorem}
\newtheorem{Proposition}[equation]{Proposition}
\newtheorem{Lemma}[equation]{Lemma}
\newtheorem{Corollary}[equation]{Corollary}

% This removes the italics
\theoremstyle{remark}
\newtheorem{Remark}[equation]{Remark}
\newtheorem{Example}[equation]{Example}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% personal macros

% natural numbers, real numbers
\newcommand{\N}{\mathbb{N}}
\newcommand{\R}{\mathbb{R}}

% macros for End(X) and Hom(X,Y)
\DeclareMathOperator{\End}{End}
\DeclareMathOperator{\Hom}{Hom}

% for f:X -> Y; the default spacing isn't great
\newcommand{\map}[2]{\,{:}\,#1\!\longrightarrow\!#2}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}    % start of the "text" in the document
\onehalfspacing


% roman page numbers for the initial pages
% \pagenumbering{roman}

% uncomment this to change the date on the title page
%\renewcommand{\Today}{October ????}
\maketitle          % creates the title page
\tableofcontents    % creates the table of contents


% uncomment the following if you want to put each chapter
%  into aseperate file

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% \includeonly{chapt2}
% \include{intro}
%
% % reset the page numbering and change to arabic numbers
% \newpage\setcounter{page}{1}\pagenumbering{arabic}
%
% \include{chapt1}
% \include{chapt2}
% \include{chapt3}
% \include{chapt4}
%
% \include{references}
%
% \end{document}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter*{Introduction}
% Big picture
Decomposing a surface or higher-dimensional manifold into discrete units, such as triangles and tetrahedra, is a standard technique used across a range of disciplines. This process, known as triangulation, transforms the analytic problem of studying a continuous space into a combinatorial one, thereby opening it up to a range of computational methods. Applications of triangulation are widespread. In physics, they appear in the Regge calculus of general relativity \cite{Regge1961} and causal dynamical triangulations of quantum gravity \cite{Ambjorn2004}, where spacetime is discretised for simulations. Engineering disciplines use meshes—a form of triangulation—to approximate structures like wings or bridges for finite element analysis \cite{Courant1994}. Triangulations are also fundamental in computer graphics for rendering objects \cite{Gouraud1998} and in data science for topological data analysis \cite{Zomorodian2004}. Within mathematics, they are used to compute topological invariants like homology groups \cite{Hatcher2005}, study combinatorial Ricci flows in differential geometry \cite{Chow2003}, and have been instrumental in graph theory, for instance, in the proof of the four-colour theorem \cite{Kenneth1977}. A key challenge is that triangulations of a given space are not unique, and their suitability depends on the specific application. For instance, algebraic topology often seeks triangulations with the minimum number of faces \cite{Hatcher2005}, whereas computer graphics prioritises triangulations that best approximate the original surface geometry. Consequently, significant research has focused on understanding the space of all possible triangulations for a given manifold and developing techniques to generate optimal ones.

% Narrowing focus
While there are various criteria for what constitutes an optimal triangulation, this report primarily explores topological and combinatorial properties. Specifically, we seek single-vertex triangulations of the $3$-sphere that correspond to interesting or complex knots. Although the techniques developed can be extended to other notions of optimality, we focus on topological and combinatorial properties because they are fundamental to the triangulation itself. These properties do not depend on specific geometric embeddings, such as the angles or sizes of the component simplices. This approach narrows the focus to abstract triangulations—which are discrete and countable—improving computational manageability and ensuring that the results are general and dependent only on the triangulation's intrinsic structure, not on extrinsic geometric factors.

% Statement of aims
The primary objective of this report is to implement, analyse, and compare a range of computational techniques for searching the space of triangulations. We investigate classical search and sampling methods, namely Markov Chain Monte Carlo (MCMC), greedy search, and simulated annealing. While greedy search algorithms have been a central tool in this field, MCMC is a more recent technique \cite{Altmann2025}. We further adapt the MCMC framework to implement simulated annealing. Additionally, we lay the groundwork for a new approach using transformer-based models to explore the space. This opens the door for reinforcement learning, a field with a growing repertoire of successes in complex problems, from game playing \cite{Silver2016} and algorithm discovery \cite{Mankowitz2023} to mathematical conjecture \cite{Davies2021, Novikov2025}.

% Roadmap
The report is structured as follows:
\begin{itemize}
    \item Chapter 1 introduces the necessary preliminary concepts, including manifolds, knot theory, and an overview of relevant statistical and machine learning techniques.
    \item Chapter 2 provides a detailed outline and discussion of the specific algorithms implemented, including justifications for our design choices.
    \item Chapter 3 presents a description and analysis of a series of numerical experiments conducted on five different search problems.
    \item Chapter 4 concludes with a discussion of our findings and outlines directions for future research.
\end{itemize}

\chapter{Preliminaries}
\section{Mathematical Preliminaries}
\subsection{Manifolds}
We begging by recalling the definition of a ``manifold'' and introducing a ``piecewise linear manifold''. Piecewise linear manifolds are fundamentally related to triangulations - the central objects we will be studying. 

A $d$-dimensional manifold, or $d$-manifold, is a topological space that generalises the notion of a surface by being locally homeomorphic to Euclidean space, $\mathbb{R}^d$. More precisely, we recall the following definitions.

\begin{Definition}[Second Countable]
A topological space $(\mathcal{M}, \tau_\mathcal{M})$ is \textbf{Second Countable} if the topology $\tau_\mathcal{M}$ of $\mathcal{M}$ has a countable base.
\end{Definition}
\begin{Definition}[Hausdorff]
A topological space $(\mathcal{M}, \tau_\mathcal{M})$ is \textbf{Hausdorff} if for any two distinct points $x, y \in \mathcal{M}$, there exist neighbourhoods $U$ of $x$ and $V$ of $y$ such that $U\cap V=\varnothing$.
\end{Definition}

With these, we can formally define a manifold.
\begin{Definition}[$d$-dimensional manifold]
A $d$-\textbf{dimensional manifold} is a Hausdorff, second-countable topological space $\mathcal{M}$ where for every point $p\in\mathcal{M}$ there is a neighbourhood $U(p)$ of $p$ that is homeomorphic to an open subset of Euclidean space $\mathbb{R}^d$.
\end{Definition}

\begin{Remark}
The condition of having a neighbourhood homeomorphic to an open subset of $\mathbb{R}^d$ is equivalent to stating that each point is either isolated (if $d=0$) or has a neighbourhood homeomorphic to all of $\mathbb{R}^d$.
\end{Remark}

\begin{Remark}
We will refer to a $d$-manifold simply as a manifold. In other contexts, this might be called a \textit{topological manifold} to distinguish it from objects with additional structure (c.f. \textit{differentiable manifold, Riemannian manifold, etc.}).
\end{Remark}

Common examples of manifolds include the circle $S^1$, the sphere $S^2$, the torus $T^2$, and Euclidean space $\mathbb{R}^d$. Some non-examples include the disk $D^2$, because its boundary points have no neighbourhood homeomorphic to an open subset of $\mathbb{R}^2$; the figure-eight curve, because at the crossing point no neighbourhood is homeomorphic to an open subset of $\mathbb{R}$; and the line with two origins, because it is not Hausdorff.

In the study of triangulations, we are often interested in an additional structure known as a \textit{piecewise-linear structure}, or \textit{PL-structure}. Intuitively, a PL-structure allows a manifold to be realised as a collection of ``flat pieces'' joined together linearly. For instance, $S^1$ admits a PL-structure that can be realised as the boundary of a triangle or a square. Two PL-manifolds (manifolds with a PL-structure) are \textit{PL-homeomorphic} if they can be transformed into each other via a homeomorphism that is itself piecewise-linear. A formal treatment of PL-structures in terms of charts and atlases can be found in introductory texts on geometric topology (e.g., ``Introduction to piecewise-linear topology'' \cite{Rourke2012}).

A key result for this work, due to Radó \cite{Rado1925} and Moise \cite{Moise1977}, establishes an equivalence between topological and piecewise-linear structures in low dimensions.

\begin{Theorem}[Hauptvermutung, simplified]
For dimensions $d \leq 3$, every manifold admits a PL-structure that is unique up to PL-homeomorphism.
\end{Theorem}

\begin{Remark}
This theorem does not hold for dimensions four or more \cite{Milnor1961}.
\end{Remark}

As this work focuses on manifolds of dimension 3, we will often treat a 3-manifold and its unique PL-structure as equivalent.

\subsection{Triangulations}
We begin by defining \textit{simplices}, the fundamental building blocks of triangulations.

\begin{Definition}[Simplex]
A $d$-simplex $\Delta$ is the $d$-dimensional convex hull of $d+1$ affinely independent vertices.
\end{Definition}

A 0-simplex is a point, a 1-simplex is a line segment, a 2-simplex is a triangle, and a 3-simplex is a tetrahedron. For any $i<d$, any subset of $i+1$ vertices of a $d$-simplex forms an $i$-dimensional simplex that we call an $i$-\textbf{dimensional face} of the original simplex. One way to construct an $d-$simplex is by taking the \textit{join} of $d$ points where we recall that
\begin{Definition}[Join]
    For two topological spaces $X$ and $Y$, the join denoted $X*Y$ is constructed by taking $X\times Y\times[0,1]$ and taking the quotient by the equivalence relation $(x, y, 0)\sim(x,y',0)$ and $(x, y, 1)\sim(x',y,1)$ for $x,x'\in X$ and $y,y'\in Y$.
\end{Definition}
For for $i<d$, any subset of $(i+1)$ points of an $d-$simplex forms another simplex that we call an $i-$\textbf{dimensional face}.

\begin{Definition}[Boundary of a Simplex]
For a $d$-simplex $\Delta$, the boundary, denoted $\partial\Delta$, is the union of all its $(d-1)$-dimensional faces.
\end{Definition}

We can take simplices and glue them together along their faces to form more complex geometric structures.
\begin{Definition}[Face Gluing]
For two $d$-simplices, $\Delta_1$ and $\Delta_2$, and two of their respective $i$-dimensional faces, $F_1\subseteq \Delta_1$ and $F_2\subseteq \Delta_2$, a \textbf{face gluing} is the space $\Delta_1\sqcup \Delta_2/\sim$ obtained by identifying the faces via a homeomorphism, or \textit{gluing map}, between $F_1$ and $F_2$.
\end{Definition}
Typically, the gluing map is defined by a bijection between the vertices of $F_1$ and $F_2$, which is then extended linearly.

\begin{Definition}[PL-Sphere]
The PL $0$-sphere is a pair of isolated points. For integers $d>0$, the PL $d$-sphere is a PL-manifold that is PL-homeomorphic to the boundary of a $(d+1)$-simplex.
\end{Definition}

\begin{Definition}[PL-Triangulation]
A \textbf{PL-triangulation} $T$ is a topological space constructed from a finite collection of $d$-simplices $\{\Delta_1,...,\Delta_k\}$, called \textbf{facets}, by gluing their $(d-1)$-dimensional faces together, subject to the following conditions:
\begin{enumerate}
    \item If a face is identified with itself as a result of the gluings, the identification map must be the identity.
    \item For any vertex $v$, the \textbf{link} of $v$ (the complex formed by all simplices $\sigma \in T$ such that $v$ is not a vertex of $\sigma$ but whose vertices, together with $v$, form a simplex in $T$) must be a PL $(d-1)$-sphere.
\end{enumerate}
This is a PL-triangulation of a manifold $\mathcal{M}$ if there is a PL-homeomorphism from $T$ to $\mathcal{M}$.
\end{Definition}

\begin{Remark}
    We can view PL-manifolds (manifolds with PL-structure) and PL-triangulations as the same thing in some sense. That being that for every PL-manifold there is a PL-triangulation that is compatible with it, and every PL-triangulation is a PL-manifold.
\end{Remark}

\subsection{Knot Theory}
This section introduces fundamental concepts from knot theory, building upon standard results from algebraic topology. For a comprehensive background reference, see Hatcher's ``Algebraic Topology'' \cite{Hatcher2005}. We are particularly interested in understanding the ``Alexander polynomial'', as this will involved in many of the search problem we are examining.

\begin{Definition}[Ambient Isotopy]
For a pair of manifolds $N$ and $M$ and embeddings $g, h$ of $N$ into $M$, an \textbf{ambient isotopy} from $g$ to $h$ is a continuous map $F:M\times[0,1]\to M$ such that for each $t\in[0,1]$, the map $F_t:M\to M$ is a homeomorphism, $F_0$ is the identity map, and $F_1\circ g=h$.
\end{Definition}

\begin{Definition}[Knot]
A \textbf{knot} is a smooth embedding of the circle $S^1$ into the 3-sphere $S^3$.
\end{Definition}

\begin{Remark}
We often refer to a knot as both the embedding function and its image in $S^3$. When we say ``a knot $K$'', we typically mean the image of the embedding.
\end{Remark}

\begin{Definition}[Knot Equivalence]
Two knots are \textbf{equivalent} if there is an ambient isotopy between their respective embedding functions.
\end{Definition}

\begin{Definition}[Knot Invariant]
A \textbf{knot invariant} is a quantity or property assigned to a knot $K$ that is the same for all knots equivalent to $K$.
\end{Definition}

\begin{Remark}
A knot invariant is not necessarily unique; non-equivalent knots may share the same invariant.
\end{Remark}

\begin{Definition}[Knot Complement]
For a knot $K$, its \textbf{tubular neighbourhood} $\nu(K)$ is a small, closed, 3-dimensional region surrounding $K$ that is homeomorphic to the solid torus $S^1\times D^2$. The \textbf{knot complement} is the space $X_K=S^3\setminus \nu(K)$.
\end{Definition}

% --- DIAGRAM REMINDER ---
% Please insert a diagram of the trefoil knot and its tubular neighbourhood here.
% For example: [Diagram of the trefoil knot, its tubular neighbourhood, and the resulting complement]
% -------------------------

The boundary of the knot complement, $\partial X_K$, is a torus, $\partial X_K\cong T^2$. A central knot invariant for this project is the Alexander polynomial, the definition of which requires the following concepts.

\begin{Definition}[Infinite Cyclic Cover]
For the knot complement $X_K$, a cover $\tilde{X}_K$ of $X_K$ is an \textbf{infinite cyclic cover} if the group of deck transformations $\operatorname{Deck}(\tilde{X}_K/X_K)$ is isomorphic to the infinite cyclic group $\mathbb{Z}$.
\end{Definition}
Every knot complement has a unique infinite cyclic cover. This follows from the fact that its first homology group is infinite cyclic, $H_1(X_K;\mathbb{Z})\cong \mathbb{Z}$ (a result of Alexander duality), and from the classification theorem for covering spaces.

\begin{Definition}[Alexander Module]
For a knot $K$, consider the infinite cyclic cover $\tilde{X}_K$ of its complement. The deck transformation group of this space is isomorphic to $\mathbb{Z}$ and is generated by some transformation $t$. We form the ring of Laurent polynomials $\Lambda=\mathbb{Z}[t, t^{-1}]$. The \textbf{Alexander module} is the first homology group $H_1(\tilde{X}_K; \mathbb{Z})$, viewed as a module over the ring $\Lambda$.
\end{Definition}

\begin{Definition}[Elementary Ideal]
For a module $M$ over a unique factorisation domain $R$ with a presentation of $n$ generators $g_i$ and $m$ relations $r_j=\sum_{i=1}^{n} a_{ji}g_i=0$, we construct the $m\times n$ presentation matrix $A=(a_{ji})$. The $k$-th \textbf{elementary ideal} is the ideal $E_k(M)$ generated by all $(n-k)\times (n-k)$ minors of $A$.
\end{Definition}
\begin{Theorem}
The elementary ideals are independent of the chosen presentation of the module.
\end{Theorem}

\begin{Definition}[Alexander Polynomial]\label{def:alex-poly}
The \textbf{Alexander Polynomial}, $\Delta_K(t)$, is the generator of the first elementary ideal of the Alexander module. This ideal is principal, and its generator is unique up to multiplication by a unit in $\Lambda$, i.e., a factor of $\pm t^k$ for some integer $k$.
\end{Definition}

\begin{Theorem}
The Alexander polynomial is a knot invariant.
\end{Theorem}
The proof that this is a well-defined knot invariant is originally due to J. W. Alexander \cite{Alexander1928}.


\subsection{Isomorphism Signatures}
We say that two PL-triangulations are \textit{combinatorially isomorphic} if they are identical up to a relabelling of their faces. Since the initial labelling of a triangulation's components is arbitrary, a canonical representation is necessary for unique identification and comparison. While specific implementations vary, the general algorithm to produce a canonical labelling is as follows.

\begin{enumerate}
    \item For each facet, calculate an initial, labelling-independent invariant (e.g., the number of distinct facets glued to its boundary faces).
    \item Partition the facets into bins based on the value of this invariant. This initial partitioning is canonical.
    \item For each facet, generate a new identifier based on the current partition of its neighbours (i.e., which bins its adjacent facets belong to). Use these new identifiers to refine the partition; if facets within the same bin now have different identifiers, the bin is split.
    \item Repeat the refinement process until the partition stabilises. If this process does not result in each bin containing a single, unique facet, an arbitrary but deterministic choice is made to break a tie and continue the algorithm.
    \item If any arbitrary choices were required, the entire process is repeated for each possible choice, generating a set of potential canonical labellings. The final isomorphism signature string is derived from each, and the lexicographically smallest string is chosen as the definitive canonical representation.
\end{enumerate}


The specific canonical labelling algorithm used in this work is that implemented in the 3-manifold software Regina \cite{Regina}, which includes details on the initial invariant and various optimisations. In the worst-case, this process takes $\mathcal{O}((d+1)! \cdot n^2)$ time, where $d$ is the dimension and $n$ is the number of facets. For a 3-dimensional triangulation, the $(d+1)! = 24$ term is a small constant, making the algorithm efficient in practice.

Once a canonical labelling is found, an ``isomorphism signature'' is calculated. For a 3-dimensional triangulation, the signature must encode the number of tetrahedra and, for each face of each tetrahedron, the identity of the tetrahedron it is glued to and the orientation of the gluing. The destination tetrahedron and the vertex permutation uniquely determine the destination face, so it does not need to be stored explicitly. To store this information efficiently as a string, the following procedure is used:
\begin{enumerate}
    \item For each face of each tetrahedron, an integer is calculated as $v_i = (6 \cdot \text{destination\_id}) + \text{permutation\_id}$. The \verb`destination_id` is the canonical index of the target tetrahedron, and the \verb`permutation_id` is an integer from 0 to 5 representing one of the $3!=6$ possible vertex mappings for the gluing. This value will be less than $6n$ for a triangulation with $n$ facets.
    \item A sequence $(v_0, v_1, \dots, v_{4n-1})$ is created by iterating through the tetrahedra in their canonical order, and for each tetrahedron, iterating through its four faces in a fixed local order.
    \item These values are combined into a single large integer: $I = v_0 + v_1(6n) + v_2(6n)^2 + \dots + v_{4n-1}(6n)^{4n-1}$.
    \item The integer $I$ is converted to a base-64 string for compact storage.
    \item The number of tetrahedra, $n$, is converted to a string and prepended to the string representation of $I$.
\end{enumerate}
This process yields a unique string that serves as the combinatorial isomorphism signature for any given 3-manifold triangulation, within practical limits on the number of facets $n$.

\subsection{Pachner Moves and the Pachner Graph}
A Pachner move is a local transformation that modifies a PL-triangulation without changing the underlying topology of the manifold. In two dimensions, the simplest example is an ``edge flip'', where two adjacent triangles are replaced by two different triangles that span the same quadrilateral region.

This concept can be generalised to higher dimensions.

\begin{Definition}[Complementary Triangulation]
Let $\Delta$ be a $(d+1)$-simplex and let $A$ be a connected subcomplex of its boundary $\partial \Delta$. The \textbf{complementary triangulation} of $A$ is the subcomplex $B=\partial\Delta \setminus A$.
\end{Definition}

\begin{Definition}[Pachner Move]
For a $d$-dimensional PL-manifold, a \textbf{Pachner move} is a local replacement of a subcomplex. It involves identifying a collection of facets that is combinatorially equivalent to a subcomplex $A \subset \partial\Delta^{d+1}$ and replacing it with the corresponding complementary triangulation $B = \partial\Delta^{d+1} \setminus A$.
\end{Definition}

The following theorem, due to Pachner \cite{Pachner1991}, establishes the fundamental importance of these moves.
\begin{Theorem}\label{thm:pachner-connected}
Two triangulations, $T$ and $T'$, represent the same PL-manifold if and only if one can be transformed into the other through a finite sequence of Pachner moves.
\end{Theorem}

For triangulations of 3-manifolds, there are two fundamental pairs of inverse Pachner moves:
\begin{itemize}
    \item The \textbf{(2,3)-move} and its inverse, the \textbf{(3,2)-move}. The (2,3)-move acts on two tetrahedra that share a common triangular face. These two tetrahedra are removed and replaced by three tetrahedra that share a common edge connecting the two vertices opposite the original shared face. The (3,2)-move is the reverse of this process.
    \item The \textbf{(1,4)-move} and its inverse, the \textbf{(4,1)-move}. The (1,4)-move acts on a single tetrahedron, which is subdivided into four smaller tetrahedra by introducing a new vertex in its interior. The (4,1)-move is the reverse, removing an interior vertex of degree four and replacing the four surrounding tetrahedra with a single one.
\end{itemize}

Since any two triangulations of a specific PL-manifold can be reached from one another through Pachner moves, we can define a graph structure on the space of triangulations.

\begin{Definition}[Pachner Graph]
For a given PL-manifold $\mathcal{M}$, the \textbf{Pachner graph} is the graph $(V, E)$ where the set of vertices $V$ is the set of all combinatorial isomorphism classes of triangulations of $\mathcal{M}$, and an edge $(v_i, v_j)\in E$ exists if and only if the triangulations $v_i$ and $v_j$ are related by a single Pachner move.
\end{Definition}

By Theorem~\ref{thm:pachner-connected}, the Pachner graph is connected for any PL-manifold. The graph is, however, infinite. We can stratify the vertices of the Pachner graph into ``levels'', where each level contains all triangulations with a fixed number of facets.

\begin{Theorem}
The number of vertices in the Pachner graph (i.e., the number of non-isomorphic triangulations) grows super-exponentially with its level.
\end{Theorem}

Notice that the (2,3) and (3,2) moves preserve the number of vertices in the triangulation, while the (1,4) and (4,1) moves change it. We are often interested in ``single-vertex'' triangulations, which can be explored using only the vertex-preserving moves. A key result for this subclass, due to Matveev \cite{Matveev2007}, is that this restricted graph is still connected for the 3-sphere.

\begin{Theorem}
Any single-vertex triangulation of the 3-sphere $S^3$ with at least two tetrahedra can be reached from any other such triangulation through a sequence of only (2,3) and (3,2) moves.
\end{Theorem}

We can analogously define the Pachner graph for 1-vertex triangulations of $S^3$, which is also a connected graph. It is currently an open question whether the number of vertices in this restricted graph grows exponentially or super-exponentially with its level.

\section{Machine Learning and Computational Preliminaries}
\subsection{Computational Complexity}
An understanding of computational complexity is crucial for motivating the search and learning-based approaches used in this thesis, as many fundamental problems in topology are computationally intractable.

\begin{Definition}[Time Complexity]
For an algorithm with input size $n$, the \textbf{time complexity} is the asymptotic worst-case number of elementary operations the algorithm performs, written in ``Big-O'' notation as $\mathcal{O}(g(n))$.
\end{Definition}

\begin{Definition}[Space Complexity]
For an algorithm with input size $n$, the \textbf{space complexity} is the asymptotic worst-case amount of memory the algorithm requires, written in ``Big-O'' notation as $\mathcal{O}(g(n))$.
\end{Definition}

\begin{Definition}[Decision Problem]
A \textbf{decision problem} is a problem that can be answered with either ``yes'' or ``no''.
\end{Definition}

\begin{Definition}[Decidable]
A decision problem is \textbf{decidable} if there exists an algorithm that is guaranteed to provide the correct answer for any input in a finite amount of time. Conversely, the problem is \textbf{undecidable} if no such algorithm exists.
\end{Definition}

\begin{Remark}
Many computational problems can be rephrased as decision problems. For example, the optimisation problem ``find the shortest path between two nodes'' can be converted into the decision problem ``does a path of length at most $k$ exist between these two nodes?''.
\end{Remark}

\begin{Definition}[Complexity Class]
A \textbf{complexity class} is a set of problems solvable under a given model of computation within a specified resource bound. For the standard Turing machine model, some major complexity classes are:
\begin{enumerate}
    \item $P$: Solvable in polynomial time.
    \item $NP$: A ``yes'' solution can be verified in polynomial time.
    \item $\operatorname{co}NP$: A ``no'' solution can be verified in polynomial time.
    \item $PSPACE$: Solvable using a polynomial amount of memory.
    \item $EXPTIME$: Solvable in exponential time.
\end{enumerate}
Many other complexity classes exist for various computational models and resource constraints.
\end{Definition}

\begin{Remark}
The distinction between $NP$ and $\operatorname{co}NP$ is important. For instance, determining if a graph has a Hamiltonian path (a path visiting each node exactly once) is in $NP$, as a proposed path can be easily verified. However, its complement—determining that no such path exists—is in $\operatorname{co}NP$, and it is widely believed that no simple certificate exists to prove the absence of such a path.
\end{Remark}

\begin{Remark}
The definitions of $NL$ and $NP$ provided here are based on the concept of a verifiable ``certificate'' for a solution. The formal definitions use non-deterministic Turing machines, but these two formulations can be shown to be equivalent.
\end{Remark}

\begin{Theorem}
The following inclusions hold for the major complexity classes:
$$ P\subseteq NP\subseteq PSPACE\subseteq EXPTIME $$
\end{Theorem}

\begin{Remark}
It is unknown whether any of these inclusions are proper. The question of whether $P=NP$ is the most famous unsolved problem in computer science.
\end{Remark}

\begin{Definition}[Hard Problem]
For a complexity class $C$, a problem $P_1$ is $C$-\textbf{hard} if every problem $P_2 \in C$ can be reduced to $P_1$ by an algorithm that is efficient relative to the complexity of $C$.
\end{Definition}

\begin{Remark}
For complexity classes like $NP$ and $PSPACE$, an ``efficient'' reduction is one that runs in polynomial time.
\end{Remark}

\begin{Definition}[Complete Problem]
For a complexity class $C$, a problem $P$ is $C$-\textbf{complete} if it is $C$-hard and $P\in C$.
\end{Definition}

In practice, problems in $P$ are considered computationally tractable. In contrast, all known algorithms for $NP$-complete problems require resources that grow exponentially with the input size, quickly becoming computationally infeasible. If a problem is proven to be $NP$-complete or harder, it implies that efficient, exact solutions are unlikely to exist, and we must often resort to heuristics or approximation algorithms.

The following theorems classify the computational difficulty of the core geometric problems addressed in this thesis, motivating our use of heuristic search methods.

\begin{Theorem}
Finding the shortest path between two triangulations on the Pachner graph is $PSPACE$-complete.
\end{Theorem}

\begin{Theorem}[Novikov-Boone]
\label{thm:trivial-presentation-undecidable}
Determining if a given group presentation defines the trivial group is undecidable.
\end{Theorem}

\begin{Theorem}
Recognising if a given 3-dimensional triangulation is homeomorphic to the 3-sphere, $S^3$, is in $NP\cap \operatorname{co}NP$.
\end{Theorem}
This result implies that both a "yes" (it is $S^3$) and a "no" (it is not $S^3$) answer have efficiently verifiable proofs. Problems in this class are not believed to be $NP$-complete.

\begin{Theorem}
Determining if a given knot is the unknot is in $NP\cap \operatorname{co}NP$.
\end{Theorem}

\subsection{Markov Chain Monte Carlo}
We now examine one of the fundamental sets of process that we will be using - Markov chain Monte Carlo. This set of process is particularly general and allows us to generate samples from a space according to some given probability distribution, with the only requirements being that for any point in our space, we can generate a new point with some known probability, and we know the probability density function (up to normalisation) of the probability distribution that we are interested in sampling from.

We will begin by giving an abstract examination of Markov chain Monte Carlo in terms of measure theory. While this examination is interesting and expands our depth of understanding, we will only practically be using the results from definition~\ref{def:mha}.

\begin{Definition}[Markov Chain]
A \textit{Markov Chain} is a sequence of random variables $x_0, x_1, x_2, \dots$ indexed by ``time'', where the sequence possesses the \textit{Markov Property}—that is, the distribution of $x_{t+1}$ depends only on the value of $x_t$.
\end{Definition}

Monte Carlo methods are a broad class of algorithms that use random sampling to obtain numerical results, often to approximate complex integrals or probability distributions. \textit{Markov Chain Monte Carlo} (MCMC) is a specific class of these methods for sampling from a probability distribution by constructing a Markov Chain whose equilibrium distribution is the desired one.

\begin{Definition}[Markov Transition Kernel]
Let $(\mathcal{X}, \mathcal{F})$ be a measurable space. A \textit{Markov Transition Kernel} is a function $P:\mathcal{X}\times\mathcal{F}\to[0, 1]$ such that:
\begin{enumerate}
    \item for any $x\in\mathcal{X}$, the function $A\mapsto P(x, A)$ is a probability measure on $(\mathcal{X}, \mathcal{F})$;
    \item for any $A\in\mathcal{F}$, the function $x\mapsto P(x, A)$ is a measurable function.
\end{enumerate}
\end{Definition}

The Markov Transition Kernel describes the evolution of the system's probability distribution. If at time $t$ the system is distributed according to a measure $\nu_t$, then the distribution at time $t+1$ is given by
\begin{equation}
    \nu_{t+1}(A) = (\nu_t P)(A)=\int_\mathcal{X}P(x, A)d\nu_t(x).
\end{equation}

\begin{Definition}[Target Distribution]
A probability distribution $\pi$ is the \textbf{target distribution} for a Markov Transition Kernel $P$ if the following two conditions hold:
\begin{enumerate}
    \item \textbf{Stationarity}: $\pi P=\pi$.
    \item \textbf{Ergodicity}: For $\pi$-almost all starting points $x_0$, the distribution of the chain's state after $n$ steps converges to $\pi$ in total variation norm, $$\lim_{n\to\infty}\|P^n(x_0,\cdot)-\pi(\cdot)\|_{TV}=0.$$
\end{enumerate}
\end{Definition}

\begin{Remark}
A statement is true for ``$\pi$-almost all $x_0$'' if the set of $x_0$ for which it is false has measure zero under $\pi$.
\end{Remark}

Directly proving stationarity and ergodicity can be difficult. Instead, a set of sufficient conditions is often used.

\begin{Theorem}
For a Markov transition kernel $P$, if the following conditions hold for a distribution $\pi$, then $\pi$ is the unique target distribution for $P$:
\begin{enumerate}
    \item \textbf{$\pi$-irreducibility}: For any set $A\in\mathcal{F}$ with $\pi(A)> 0$, there exists some $n$ such that $P^n(x, A)>0$ for all $x\in\mathcal{X}$. (This ensures the chain can reach any part of the state space from any starting point).
    \item \textbf{Aperiodicity}: The chain is not trapped in deterministic cycles.
    \item \textbf{Recurrence}: The chain is guaranteed to return to any given region of the space.
    \item \textbf{Reversibility (Detailed Balance)}: For any two measurable sets $A, B\in\mathcal{F}$, we have $$\int_AP(x, B)d\pi(x)=\int_BP(x,A)d\pi(x).$$ (This is a stronger condition than stationarity that is often easier to satisfy).
\end{enumerate}
\end{Theorem}

By the Ergodic Theorem for Markov chains, for any integrable function $f$ of the state (an observable), the sample average converges to the true expectation under the target distribution: $S_n=\frac{1}{n}\sum_i^n f(x_i)\to \mathbb{E}_\pi[f]$. The error of this approximation typically decreases at a rate of $\mathcal{O}(1/\sqrt{n})$.

\begin{Definition}[Metropolis-Hastings Algorithm]\label{def:mha}
Given a function $f(x)$ that is proportional to the target probability density, $f(x) \propto \pi(x)$, and a proposal distribution $g(x'|x)$, the Metropolis-Hastings algorithm generates a sequence of samples as follows:
Initialise $x_0$. For each step $t=0, 1, 2, \dots$:
\begin{enumerate}
    \item Propose a new state $x'$ according to $g(x'|x_t)$.
    \item Compute the acceptance ratio $\alpha = \frac{f(x')}{f(x_t)}$.
    \item Sample $u$ from a uniform distribution on $[0, 1]$.
    \item If $\alpha > u$, accept the new state by setting $x_{t+1}=x'$. Otherwise, reject and set $x_{t+1}=x_t$.
\end{enumerate}
\end{Definition}

\begin{Theorem}
If the proposal function $g$ is symmetric (i.e., $g(x|y)=g(y|x)$), the Markov chain generated by the Metropolis-Hastings algorithm has $\pi$ as its target distribution.
\end{Theorem}

\begin{Remark}
If the proposal distribution is not symmetric, the acceptance ratio must be modified by the Hastings ratio, $\alpha_H=\alpha\cdot\frac{g(x_t|x')}{g(x'|x_t)}$, to maintain detailed balance.
\end{Remark}

\subsubsection{Statistics in MCMC}
For any finite number of samples $n$, the empirical distribution may not have converged to $\pi$. This is particularly common if $\pi$ is multi-modal, as the chain can become ``stuck'' in one mode. Consequently, statistical diagnostics are used to assess convergence, typically by running multiple independent chains.

\begin{Definition}[Variance Components]
Let there be $J$ chains, each of length $L$, with samples $x_1^j, \dots, x_L^j$ for the $j$-th chain.
\begin{enumerate}
    \item \textbf{Between-chain variance}: $B=\frac{L}{J-1}\sum_{j=1}^{J}(\bar{x}_j-\bar{x}_*)^2$, where $\bar{x}_j$ is the mean of chain $j$ and $\bar{x}_*$ is the global mean. This measures the variance between the means of each chain.
    \item \textbf{Within-chain variance}: $W=\frac{1}{J}\sum_{j=1}^{J}s_j^2$, where $s_j^2$ is the sample variance of chain $j$. This is the average of the individual chain variances.
\end{enumerate}
\end{Definition}

From these components, we can estimate the total variance of the underlying distribution.
\begin{Theorem}[Gelman-Rubin Variance Estimate]
An estimate for the total variance of the target distribution, accounting for both within- and between-chain variation, is given by
$$\hat{V}=\frac{L-1}{L}W+\frac{1}{L}B.$$
\end{Theorem}

This leads to a practical convergence diagnostic.
\begin{Definition}[Gelman-Rubin Statistic]\label{def:gelman-rubin}
The Gelman-Rubin statistic, or potential scale reduction factor, is
$$\hat{R}=\sqrt{\frac{\hat{V}}{W}}.$$
\end{Definition}
If the chains have converged, they are all sampling from the same distribution, so the within-chain variance should approximate the total variance, yielding $\hat{R} \approx 1$. A value of $\hat{R} > 1$ indicates that the between-chain variance is still large compared to the within-chain variance, suggesting the chains have not yet fully explored the state space. A common heuristic is to require $\hat{R} < 1.01$ to indicate convergence.

\subsection{Simulated Annealing}
For a measurable space $(\mathcal{X}, \mathcal{F}, \mu)$, we may have a measurable function $E:\mathcal{X}\to\mathbb{R}$, often called an ``energy'' or ``cost'' function. Simulated annealing is a probabilistic optimisation metaheuristic inspired by the annealing process in metallurgy. The core idea is to sample from the temperature-dependent Gibbs distribution, $\pi_{T}(x) \propto e^{-E(x)/T}$, while gradually lowering the temperature parameter $T$.

Simulated annealing is an MCMC method where the target distribution, $\pi_T$, changes over time. When using the Metropolis-Hastings algorithm with a symmetric proposal, the acceptance ratio for a move from state $x$ to $x'$ at temperature $T$ is
$$ \alpha = \frac{\pi_T(x')}{\pi_T(x)} = \frac{e^{-E(x')/T}}{e^{-E(x)/T}} = e^{-(E(x')-E(x))/T}. $$

This creates a trade-off between exploration and exploitation. At high temperatures ($T \gg 1$), the acceptance probability for energetically unfavourable moves (where $E(x') > E(x)$) is high, allowing the chain to traverse the state space freely and escape local minima. As the temperature is lowered ($T \to 0$), the probability of accepting such ``uphill'' moves vanishes, causing the algorithm to behave like a greedy search that settles into the nearest energy minimum.

The performance of simulated annealing is highly dependent on the choice of a ``cooling schedule''—the rate at which the temperature $T$ is decreased. While theoretically a sufficiently slow cooling schedule guarantees convergence to the global minimum, in practice this may require an infeasibly long runtime, and the method is used as a heuristic to find good, though not necessarily optimal, solutions.


\section{Deep Learning}
\subsection{Transformers}\label{subsec:transformers}
Similar to the section on Markov chain Monte Carlo, we will begin by providing an abstract definition of transformers to provide a greater depth of understanding. Practically we will only be using the results from definition~\ref{def:stand-trans-head} onwards.

\begin{Definition}[Row Operator]
For a field $F$ and a function $s:F^d\to F^d$, define the \textbf{row operator} $\mathcal{R}_s:M_d(F)\to M_d(F)$ as the application of $s$ to each row of a matrix in $M_d(F)$. That is, $$\mathcal{R}_s\left((r_1, r_2, \dots, r_d)^T\right)=\left(s(r_1), s(r_2), \dots, s(r_d)\right)^T.$$
\end{Definition}

\begin{Definition}[Abstract Transformer Head]
Let $(v_1, v_2, \dots, v_d)$ be a collection of vectors in a vector space $V$ over a field $F$. Let $\dot{V}$ be the space $V$ equipped with a bilinear form $B:V\times V\to F$. Let $G:F^d\otimes V\to M_d(F)$ be the ``Gram operator'' which computes the matrix of pairwise interactions under $B$. Let $L:V\to W$ be a linear operator and $s:F^d\to F^d$ be a function.

An \textbf{abstract transformer head} is a function $H:F^d\otimes V\to F^d\otimes W$ defined by
\begin{equation}
    H(x)=(\mathcal{R}_s(G(x))\otimes L)(x).
\end{equation}
\end{Definition}

\begin{Definition}[Abstract Multi-Head Attention]
Let $H_i$ be an abstract transformer head from $F^d\otimes V_i\to F^d\otimes W_i$ for $i=1, \dots, q$, where each $V_i$ is the space $V$ equipped with a potentially unique bilinear form. Let $O:\bigoplus_{i=1}^q W_i \to U$ be a linear operator. The \textbf{multi-head attention} is an operator $A:F^d\otimes V\to F^d\otimes U$ defined as
\begin{equation}
    A(x)=(I\otimes O)\left(\bigoplus_i H_i(x)\right).
\end{equation}
\end{Definition}

\begin{Definition}[Abstract Feedforward Network]
For a vector space $U$ over a field $F$, an \textbf{abstract feedforward network} is an operator $N:U\to W$ defined by $N(x)=L_2(a(L_1(x)))$, where $L_1:U\to V$ and $L_2: V\to W$ are linear operators and $a:V\to V$ is a non-linear function.
\end{Definition}

\begin{Definition}[Abstract Transformer Block]
An \textbf{abstract transformer block} $T:F^d\otimes V\to F^d\otimes V$ is an operator defined by the sequence of operations:
$$ y_1 = x + A(x) $$
$$ T(x) = y_1 + (I\otimes N)(y_1) $$
\end{Definition}

While these abstract formulations are theoretically rich, in practice we work over $F=\mathbb{R}$ with finite-dimensional vector spaces. This allows us to represent linear transformations as matrix multiplications and bilinear forms as $B(v_1, v_2)=v_1^T M v_2$ for some matrix $M$. The abstract components correspond to the standard implementation as follows: the Gram operator $G(x)$ is realised by projecting the input vectors into ``query'' and ``key'' spaces before computing their dot products; the row-wise function $\mathcal{R}_s$ becomes the softmax function; and the linear map $L$ is a projection into a ``value'' space. The non-linear functions are fixed or have a small number of learnable parameters. This gives a finite set of scalar parameters $\theta$ that defines the transformer block. Additionally, components for numerical stability and regularisation are introduced.

\begin{Definition}[Standard Transformer Head]\label{def:stand-trans-head}
For a collection of vectors $(v_1, \dots, v_d)$, where $v_i\in \mathbb{R}^{d_e}$, we form the matrix $X\in\mathbb{R}^{d\times d_e}$ by stacking these vectors as rows. A single attention head is calculated as:
\begin{equation}
    h(X) = \operatorname{softmax} \left( \frac{(XW^Q)(XW^K)^T}{\sqrt{d_k}}+M \right)(XW^V),
\end{equation}
where the softmax is applied row-wise. The matrices $W^Q, W^K \in\mathbb{R}^{d_e\times d_k}$ and $W^V\in\mathbb{R}^{d_e\times d_v}$ are learnable weight matrices for the ``query'', ``key'', and ``value'' projections. The term $1/\sqrt{d_k}$ is a scaling factor for gradient stability. $M\in M_d(\mathbb{R}\cup\{-\infty\})$ is an optional mask, often used in auto-regressive models to prevent positions from attending to subsequent positions.
\end{Definition}

\begin{Definition}[Standard Multi-Head Attention]
For an input $X$ and $q$ attention heads $h_1, \dots, h_q$, multi-head attention is defined as:
\begin{equation}
    MHA(X) = \operatorname{Concat}(h_1(X), \dots, h_q(X))W^O,
\end{equation}
where $\operatorname{Concat}$ joins the output matrices of each head along their feature dimension, and $W^O$ is a final learnable output projection matrix.
\end{Definition}

\begin{Definition}[Standard Feedforward Network]
For $x\in \mathbb{R}^n$, a standard two-layer feedforward network is $FFN(x)=\sigma_{\text{act}}(xW_1+b_1)W_2+b_2$, where $W_i$ are weight matrices, $b_i$ are bias vectors, and $\sigma_{\text{act}}$ is a non-linear activation function (e.g., ReLU).
\end{Definition}

\begin{Definition}[Layer Normalisation]
For a vector $x\in \mathbb{R}^d$, let $\mu_x$ and $\sigma_x$ be its mean and standard deviation. The layer normalisation of $x$ is
\begin{equation}
    LN(x)_i=\gamma_i\left(\frac{x_i-\mu_x}{\sqrt{\sigma_x^2+\epsilon}}\right) + \beta_i,
\end{equation}
where $\gamma, \beta\in\mathbb{R}^d$ are learnable scale and shift parameters, and $\epsilon$ is a small constant for numerical stability.
\end{Definition}

\begin{Definition}[Dropout]
For a rate $r\in[0, 1]$, the \textbf{dropout} operator $DO(X, r)$ randomly sets a fraction $r$ of the entries in the matrix or vector $X$ to zero during training. This is a form of regularisation to prevent overfitting.
\end{Definition}

\begin{Definition}[Standard Transformer Block]
A standard transformer block applies these components in sequence. Given an input $X$, it computes:
\begin{align*}
    X' &= X + MHA(LN(X)) \quad &\text{(Multi-head attention with residual connection)}\\
    X_{out} &= X' + FFN(LN(X')) \quad &\text{(Feedforward network with residual connection)}
\end{align*}
Dropout is typically applied after the MHA and FFN steps during training.
\end{Definition}

Because these transformer blocks map from $\mathbb{R}^{d\times d_e}$ to $\mathbb{R}^{d\times d_e}$, they can be chained together to form a deep model. For many tasks, the input is a sequence of discrete tokens rather than vectors.

\begin{Definition}[Token Embedding]
For a vocabulary of size $V$, a token is represented by a one-hot vector $v \in \{0,1\}^V$. The \textbf{token embedding} of $v$ is $h=vE$, where $E\in\mathbb{R}^{V\times d_e}$ is a learnable embedding matrix. This projects the sparse, high-dimensional token vector into a dense, lower-dimensional space.
\end{Definition}

The transformer block is permutation-invariant, so to incorporate sequential information, we use:
\begin{Definition}[Positional Encoding]
For a sequence of embedded vectors $(h_0, h_1, \dots, h_{d-1})$, a \textbf{positional encoding} is added to each vector. This is typically done by adding a vector $P_i$ from a pre-defined or learned matrix $P \in \mathbb{R}^{D_{max}\times d_e}$ to the input vector $h_i$, where $i$ is the position in the sequence. Thus, the final input to the first transformer block is $h_i' = h_i + P_i$.
\end{Definition}

A prototypical example is the GPT-2 model. A sequence of words is converted to a sequence of token embeddings, to which positional encodings are added. This input is then processed by a series of transformer blocks. The output from the final block is passed through a final layer normalisation and then a linear projection back to the vocabulary dimension. At each position $i$, this yields a vector of logits, which is passed through a softmax function to produce a probability distribution over the entire vocabulary for the next word in the sequence, $w_{i+1}$. The model is trained using a cross-entropy loss objective, comparing the predicted distribution at each position with the actual next word in the training data.

\subsection{Gradient Descent}
Given a neural network $N(x\;|\;\theta)$ with parameters $\theta\in\mathbb{R}^d$, the goal of training is typically to find a parameter set $\hat{\theta}$ that minimises a loss function $\mathcal{L}(N(x, \theta), y)$ averaged over a set of training data $\{(x_i, y_i)\}$. Since the network $N$ is a complex, non-linear function of $\theta$, this objective function cannot be minimised analytically. Instead, iterative optimisation methods like gradient descent are used.

The fundamental principle of gradient descent is to update the parameters in the opposite direction of the gradient of the loss function, $\theta_{i+1} = \theta_i - \eta \nabla_\theta \mathcal{L}(\theta_i)$, where $\eta$ is the learning rate. More formally, each step can be viewed as solving a local linear approximation of the loss function, regularised by a penalty on the step size. A single update step is the solution to:
\begin{equation}
    \theta_{i+1}=\arg\min_\theta \left(\langle g, (\theta-\theta_i)\rangle+\frac{\lambda}{2}\|\theta-\theta_i\|^2\right),
\end{equation}
where $g = \nabla_\theta \mathcal{L}(\theta_i)$ is the gradient and the second term penalises large deviations from the current point $\theta_i$.

Computing the gradient over the entire training dataset is computationally expensive. Therefore, in practice, the gradient is estimated using a small, random ``mini-batch'' of data. This approach is known as stochastic gradient descent (SGD). Because each mini-batch provides only a stochastic estimate of the true gradient, the updates can be noisy. To stabilise this process, many algorithms incorporate a momentum term, which uses an exponentially weighted moving average of past gradients.

Different choices for the norm, the gradient calculation, and the use of momentum lead to different optimisers. Common examples include:
\begin{itemize}
    \item \textit{SGD}, which typically uses the Frobenius norm and the standard stochastic gradient.
    \item \textit{Adam}, which uses exponential smoothing for both the gradient (first moment) and its squared values (second moment) to create an adaptive step size, which can be related to the $\ell_1 \to \ell_\infty$ induced norm \cite{OldOptimizerNewNorm}.
    \item \textit{Shampoo}, which uses pre-conditioning based on the spectral properties of the parameter matrices.
    \item \textit{Natural Gradient Descent (NGD)}, which uses the Fisher information matrix to define a geometry-aware update direction.
\end{itemize}

\subsection{Reinforcement Learning}
In our context, reinforcement learning is a technique for optimising a parameterised probability distribution $\pi_\theta$ from which we can sample outputs $y$. Given a reward function $R(y)$ that evaluates the quality of an output, the objective is to find parameters $\theta$ that maximise the expected reward:
\begin{equation}
    J(\theta)=\mathbb{E}_{y\sim\pi_\theta}[R(y)].
\end{equation}

A direct approach to maximising this objective is to use a policy gradient method known as REINFORCE. We perform gradient ascent on $J(\theta)$ by updating the parameters using the gradient:
\begin{equation}
    g=\nabla_\theta J(\theta)=\mathbb{E}_{y\sim\pi_\theta}[\nabla_\theta \ln(\pi_\theta(y)) R(y)].
\end{equation}
This gradient can be estimated from a batch of samples and used in a gradient descent optimiser.

A problem with using the raw reward $R(y)$ is that it can lead to high variance in the gradient estimate and instability during training. For instance, if all actions in a batch receive a high positive reward, the algorithm will try to increase the probability of all of them, even if some were significantly better than others. To address this, the reward is often replaced by an \textbf{advantage function}, $A(y)$, which measures how much better a given sample's reward is compared to the expected reward: $A(y_i) = R(y_i) - \mathbb{E}_{y\sim \pi_\theta}[R(y)]$. The expected value, or ``baseline'', can be estimated by the average reward over the current batch of samples.

\begin{Remark}
The variance of this simple baseline estimate can still be high. More advanced methods train a separate ``critic'' model to provide a learned estimate of the baseline. We do not explore this technique here.
\end{Remark}

A key challenge with policy gradient methods is that after each parameter update, the gradient estimate $\mathbb{E}_{y\sim\pi_\theta}[\dots]$ becomes invalid because the distribution has changed, requiring a new batch of samples to be generated. To improve sample efficiency, \textbf{importance sampling} allows a batch of samples drawn from an old policy $\pi_{\theta_{old}}$ to be reused for several update steps. This is achieved by re-weighting the advantage function with the importance ratio, $r(\theta)=\frac{\pi_\theta(y)}{\pi_{\theta_{old}}(y)}$:
\begin{equation}
    \mathbb{E}_{y\sim\pi_\theta}[A(y)]=\mathbb{E}_{y\sim\pi_{\theta_{old}}}[r(\theta)A(y)].
\end{equation}

This allows us to perform several steps of gradient ascent on the same batch of samples. However, after a few updates, $\pi_\theta$ can diverge significantly from $\pi_{\theta_{old}}$, causing the importance ratio to become unstable and the gradient estimate unreliable. Proximal Policy Optimisation (PPO) addresses this by constraining the updates to a ``trust region''. This is implemented by clipping the importance ratio in the objective function. If the advantage $A(y)$ is positive, we cap the increase in probability to prevent excessively large updates. This leads to the PPO-Clip objective function:
\begin{equation}
    L^{CLIP}(\theta)=\mathbb{E}_{y\sim\pi_{\theta_{old}}}[\min\left(r(\theta)A(y), \operatorname{clip}(r(\theta), 1-\epsilon, 1+\epsilon)A(y)\right)].
\end{equation}

\chapter{Problem Formulation}
We begin by simply stating the problem that we are studying. The central problem is the optimisation of an objective function over the space of manifold triangulations. Formally given the space of all triangulations of some manifold $\mathcal{M}$, denoted $\mathcal{T}(\mathcal{M})$, and some \textit{objective function} $\mathcal{O}:\mathcal{T}(\mathcal{M})\to\R$ (that is some function we are interested in maximising) we want to find some $T^*\in\mathcal{T}(\mathcal{M})$ subject to some specific size constraint that maximises this function:
\begin{equation}
    T^*=\arg\max_{T\in\mathcal{T}(\mathcal{M}),\operatorname{size}(T)\leq S_{\max}}\mathcal{O}(T)
\end{equation}
Because the space $\mathcal{T}(\mathcal{M})$ is intractably large and poorly understood, finding the global maxima is likely impossible, as are any analytic techniques. Hence, we develop and compare a series of techniques that can be used to find a specific triangulation $T\in\mathcal{T}(\mathcal{M})$ with $\mathcal{O}(T)$ significantly higher than a typical triangulation from $\mathcal{T}(\mathcal{M})$.

While the problem statement is quite general - we are specifically interested in finding triangulations that achieve large objective functions for objectives related to topological and combinatorial properties of the triangulation. In particular we are interested in those related to knots present in the single vertex triangulations of $S^3$ (details elaborated on later). The path that we will be following is
\begin{enumerate}
    \item \textbf{Establishing a Baseline:} We need to explore techniques of quantifying for a specific triangulation $T\in\mathcal{T}(\mathcal{M})$ what it means to be significantly better than a typical triangulation in $\mathcal{T}(\mathcal{M})$. We achieve this with MCMC.
    \item \textbf{Explore Classical Optimisation:} We will explore two main classical optimisation techniques to find such a $T^*$ - direct ascent and simulated annealing. Direct ascent is a slight modification of greedy search. Both of these techniques use local Pachner moves so are ``slow'' to explore the space.
    \item \textbf{Generative Modelling:} We establishing a technique that can be used to generate triangulations from $\mathcal{T}(\mathcal{M})$ using deep learning techniques. This lays the groundwork for a range of new optimisation techniques from the field of reinforcement learning. Additionally, this opens the door for doing a hybrid approach where generative models are used to propose ``random'' points on the Pachner graph, and then local search can be performed around it until it gets stuck, and then a random new point can be proposed. 
\end{enumerate}

\chapter{Search and Sampling Algorithms}
\section{Classical Techniques}
\subsection{Direct Accent}\label{sec:direct-accent}
For an objective function $\mathcal{O}:\mathcal{T}(\mathcal{M})\to\R$, for small triangulations (number of tetrahedra around 6 or lower), we can typically calculate $\mathcal{O}$ exhaustively from a census. In doing this, we may find that $\mathcal{O}$ tends to increase with more tetrahedra, this motivates the notion of direct accent.
The concept is to start with some some small triangulation, enumerate all of its neighbours that have more tetrahedra, and then sample one of these randomly, biased towards choosing one with a higher objective. This process can then be repeated to generate a chain of triangulations of increasing size, and the whole process repeated to generate multiple chains.

In order for this search technique to work, we need to be able to do two things.
\begin{enumerate}
    \item Enumerate all the neighbours of a specific triangulation $T'$ that are larger, call this set $N_+(T')$
    \item Convert from $\{\mathcal{O}(T)\;:\;T\in N_+(T')\}$ to some selection probability
\end{enumerate}
To address this first point, we consider $(2-3)$ moves. In order for a $(2-3)$ move to happen we need to have a face that is shared by two distinct tetrahedra, this face will be converted to an edge that is ``perpendicular'' in some sense. Hence, we simply iterate through all $2T$ faces and check if a $(2-3)$ move is possible, performing it if it is. The details are explained in more detail in Altmann and Spreer \cite{Altmann2025}.

\begin{Remark}
    The choice of $(2-3)$ moves is to maintain the number of vertices, $(1-4)$ moves can also be considered.
\end{Remark}

For the second point, we need to convert from a list of scores $\{\mathcal{O}_1, ..., \mathcal{O}_n\}$ to a list of probabilities $\{p_1, ..., p_n\}$ ensuring that the probability is positive and normalised to sum to one. This is a standard problem in machine learning and is addressed by the softmax function
\begin{align}
    p_i &= \frac{e^{\beta O_i}}{\sum_j e^{\beta O_j}}
\end{align}
Where $\beta>0$ is some fixed parameter, often related to the inverse of the ``temperature'' $\beta=1/T$ (where $T$ is the temperature, we will use $\beta$ to avoid confusion with a triangulation), lending from an analogy to thermal physics.

With these defined, we can now detail direct ascent in algorithm~\ref{alg:direct-accent}. The algorithm details a single run of direct ascent, this can be done multiple times to get a range of different ascent paths. So long as $\beta<\infty$ there is a possibility for unique paths. When $\beta=0$ it is essentially a random search, choosing any neighbour independent of the objective functions value. When $\beta=\infty$, the neighbour chosen is the one with the greatest objective of all neighbours.

\begin{algorithm}
\caption{Direct Accent}\label{alg:direct-accent}
\begin{algorithmic}
\State Let $T_0\in\mathcal{T}(\mathcal{M})$ be the initial triangulation.
\State Let $\beta > 0$ be a fixed parameter.
\State Let $N\in \N$ be a fixed chain size.
\State Let $\mathcal{O}:\mathcal{T}(\mathcal{M})\to \R$ be some objective function.
\For{$n=1$ to $N$}
    \State Generate all neighbours $T_{ni}$ of $T_{n-1}$ by applying $(2-3)$ moves.
    \For{each neighbours $T_{ni}$ in the set}
        \State Calculate the selection probability $p_i = \frac{e^{\beta O_i}}{\sum_j e^{\beta O_j}}$.
    \EndFor
    \State Sample $T_n$ from the set of neighbours $\{T_{ni}\}$ with probability $p_i$.
    \EndFor
    \State Return $T_N$
\end{algorithmic}
\end{algorithm}

\subsection{Markov Chain Monte Carlo}
For an objective function $\mathcal{O}:\mathcal{T}(\mathcal{M})\to \R$, we will be interested in knowing what a ``typical'' objective function value looks like. One way to do this is to adapt Markov chain Monte Carlo (MCMC) to the Pachner graph, and generate a uniform sampling of the space, calculating $\mathcal{O}$ on each member of the sample and analysing its statistical properties. The main issue with this is that the Pachner graph is infinite, so its impossible to define a uniform distribution on the space. Furthermore, the number of triangulations for a given number of tetrahedra increases incredibly quickly, and at an unknown rate. Hence, a uniform sampling across all levels would be currently impossible to prove (as the number of triangulations is unknown) and would spend ``more time'' at large triangulations simply because there are more of them. Hence, we modify the problem to the goal of returning a sample that is uniform for a given level, but is otherwise different for different levels, and in particular the probability of sampling a fixed triangulation of size $n$ tends to zero as $n$ gets larger \textbf{faster} than the number of triangulations grows, this ensures that the probability of sampling large triangulations tends to zero, moderating the size of the triangulations sampled. Altmann and Spreeer developed a specific algorithm to do this \cite{Altmann2025}. The algorithm implemented is outlined in \ref{alg:mcmc}. We note that $n(T_s)$ is the number of tetrahedra of $T_s$ and an $i-$neighbour is a triangulation resulting from an $i-$Pachner move for $i=2, 3$ is a $(3-2)$ and $(2-3)$ move respectively. The sampling procedure outlined is proven to be uniform in each level as required. However, as each level has a different probability of being sampled from, a specific level $n$ will be chosen and all other triangulations discarded - giving a uniform sample of the space of triangulations of size $n$.

This algorithm represents a single chain of MCMC, typically multiple chains are run to ensure convergence as in accordance with definition~\ref{def:gelman-rubin}.

\begin{algorithm}
\caption{MCMC for Triangulations}\label{alg:mcmc}
\begin{algorithmic}
\State Let $T_1\in\mathcal{T}(\mathcal{M})$ be the initial triangulation.
\State Let $\gamma=1/k, k\in\mathbb{N}$
\State Let $S$ be the number of samples
\State Let $\mathcal{O}:\mathcal{T}(\mathcal{M})\to \R$ be some objective function.
\For{$s=1$ to $S$}
    \State Sample $u\in U([0, 1])$ uniform
    \If{$u<e^{-\gamma n(T_s)}$}
        \State Set $i:=1$, $m:=2n$
    \Else
        \State Set $i:=2$, $m:=2n-2$
    \EndIf
    \State Enumerate $i-$neighbours $T_1',...,T_\ell'$ of $T_s$
    \State Sample $v\in U([0, 1])$ uniform
    \If{$v<\ell / m$}
        \State Set $T_{s+1}$ to a random choice of $T_1',...,T_\ell'$
    \Else
        \State Set $T_{s+1}$ to $T_{s}$
    \EndIf
\EndFor
\end{algorithmic}
\end{algorithm}

\subsection{Simulated Annealing}\label{sec:simulated-annealing}
Because the above Markov Chain Monte Carlo algorithm leads to a uniform distribution, we can use it as a proposal distribution for simulated annealing. This allows us to directly modify the MCMC algorithm to become a simulated annealing algorithm. The concept is to propose a triangulation, compare its objective function to the current objective function, if it is better move to this new triangulation, if it is worse move to the new triangulation with some probability, staying at the same triangulation otherwise. Similar to direct ascent, we need to define some way of calculating the probability of moving in the scenario that it is worse, and similar to direct ascent we chose a function
\begin{align}
    p(o_{p}, o_{c})=e^{-\beta(o_c-o_p)}
\end{align}
Where once again $\beta=1/T$ controls how much randomness is involved. Unlike direct ascent, the value of $\beta$ is usually chosen to vary from iteration to itinerate. This is called a temperature schedule. So we have $\beta_s$ for each step $s$.

The implemented standard simulated aneling algorithm is described in algorithm~\ref{alg:simulated-annealing}.

The key to this algorithm performing successfully is that we have a good choice for $\beta_s$. If it's too high we will get stuck in local maxima, and if its too low we essentially have a random walk which won't achieve much more than MCMC. As such, we pick a ``target acceptance rate''. The ``acceptance rate'' is the percentage of the time that we accept a proposal as opposed to staying still. Higher acceptance rates correspond to random walks, and lower ones correspond to the algorithm sitting in the one place. The ``target acceptance rate'' is what we want the acceptance rate to be. During sampling, we track a exponential moving average estimate for what the current acceptance rate is according to
\begin{align}
    r_s=(1-\alpha)r_{s-1}+\alpha a_s
\end{align}
Where $a_s=0$ if the move was not accepted and $a_s=1$ if the move was accepted. We then compare the moving average acceptance rate $r_s$ to the target acceptance rate $r$ and compute the difference $r_s-r$ and update $\beta$ according to
\begin{align}
    \beta_s=\beta_{s-1}e^{\lambda(r_s-r)}
\end{align}
Here $\lambda$ represents how aggressively to track the target, and $\alpha$ represents how quickly to forget past acceptance rates. This gives us an adaptive simulated annealing.

\begin{algorithm}
\caption{Simulated Annealing}\label{alg:simulated-annealing}
\begin{algorithmic}
    \State Let $T_0$ be some starting triangulation.
    \State Let $S$ be the number of samples.
    \State Let $M$ be some hash table memory.
    \State Let $\mathcal{O}:\mathcal{T}(\mathcal{M})\to \R$ be some objective function.
    \State Let $\beta_s$ be some temperature schedule.
    \For{$s=1$ to $S$}
        \State Propose $T_s'$ from $T_{s-1}$ by using $1-$step of the described MCMC algorithm.
        \State Retrieve $o_{s-1}=\mathcal{O}(T_{s-1})$ from $M$
        \State Check if $o_s=\mathcal{O}(T_s)$ is in $M$, if it is - retrieve it, if not - compute it and store it in $M$.
        \State Compute $\alpha=e^{-\beta_n(o_{s-1}-o_s)}$
        \State Generate some $p\sim U([0, 1])$
        \If{$p\leq\alpha$}
            \State Accept $T_s=T_s'$
        \Else
            \State Let $T_s=T_{s-1}$
        \EndIf
    \EndFor
\end{algorithmic}
\end{algorithm}


\section{Transformers}
\subsection{Base Transformer}
We are interested in being able to sample triangulations independently (unlike MCMC where there is a strong correlation). To achieve this, we implement a mostly standard GPT-2 style autoregressive transformer trained to generate isomorphism signatures. The most notable difference is that we embed each letter of the isomorphism signature as a token. In addition to each of the letters in the isomorhpism signature, we also include a three special tokens \verb|[BOS]|, \verb|[EOS]|, and \verb|[PAD]| for the beginning of the isomorphism signature, end of isomorphism signature, and padding to ensure that all the strings in the batch are the same size for parallelism respectively. The architecture used is described in algorithm~\ref{alg:transformer}. We refer to the list of all possible letters in an isomorphism signature as the vocabulary.

The transformer is trained for autoregressive generation. That is, if the input was \verb|[BOS]|$abc$\verb|[EOS]| we would feed \verb|[BOS]|$abc$ into the transformer and set $abc$\verb|[EOS]| as the target. The transformer predicts a vector of $V$ logits for each letter where $V$ is the size of the vocabulary. Each logit represents the transformed probability of that token coming next. The actual probability for logits $\{l_i\;|\;0\leq i\leq V\}$ can be recovered via
\begin{equation}
    p_i=\frac{e^{l_i}}{\sum_j e^{l_j}}
\end{equation}
The loss is chosen to be the categorical cross entropy which simplifies to $-\log(p_i)$ for $i$ the index of the correct token. This loss is zero if the probability of the correct token being selected is $100\%$ and is $\infty$ if the probability of picking the correct token is $0\%$.

The model is trained towards minimising this loss function with AdamW - described in Algorithm~\ref{alg:adamw}. Once the parameters of the model are fit, an isomorphism signature can be generated by starting with the \verb|[BOS]|, passing it through the transformer and getting the predicted logit vector for the last token, randomly selecting a token according to this vector and appending it to the end of the input, repeating until the \verb|[EOS]| token is generated or some maximum size is reached.

\begin{algorithm}
\caption{IsoSig Transformer}\label{alg:transformer}
\begin{algorithmic}
    \State Let $V$ be the vocabulary size
    \State Let $d_e\in\N$ the embedding dimension
    \State Let $\ell$ be the number of layers
    \State Let $h$ be the number of heads
    \State Let $r\in[0, 1]$ be the dropout rate.
    \State Let $w$ be some partially complete isomorphism signature of size $l\geq 1$
    \State Compute \verb|tok_emb|$\in \R^{l\times d_e}$ as the token embedding of each letter in $w$
    \State Compute \verb|pos_emb|$\in \R^{l\times d_e}$
    \State Compute $X=$\verb|tok_emb|$+$\verb|pos_emb|$\in \R^{l\times d_e}$
    \State Compute $X=DO(X, r)\in\R^{l\times d_e}$
    \For{$i\in[1,...,\ell]$}
        \State $X=TB(X, h, r)\in\R^{l\times d_e}$
    \EndFor
    \State Compute $X=LN(X)\in\R^{l\times d_e}$
    \State Return \verb|logit|$=MX\in \R^{l\times V}$
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{AdamW}\label{alg:adamw}
\begin{algorithmic}
    \State Let $L:\theta\to\R$ be a loss function to minimise
    \State Let $\beta_1, \beta_2, \eta, \lambda$ be fixed parameters
    \State Let $T$ be the number of steps
    \State Initialise $\theta_0$ randomly
    \For{$t=1$ to $T$}
        \State Compute $g_t=\nabla_\theta L(\theta_{t-1})$
        \State Compute $m_t=\beta_1m_{t-1}+(1-\beta_1)g_t$ and $v_t=\beta_2v_{t-1}+(1-\beta_2)g_t^2$
        \State Compute $\hat{m}_t=m_t/(1-\beta_1^t)$ and $\hat{v}_t=v_t/(1-\beta_2^t)$
        \State Update $\theta_t=\theta_{t-1}-\eta\left(\frac{\hat{m}_t}{\sqrt{\hat{v}_t}+\varepsilon}+\lambda \theta_{t-1}\right)$
    \EndFor
\end{algorithmic}
\end{algorithm}

\chapter{Numerical Experiments}
\section{Objective Functions}\label{sec:objective-functions}
To test the effectiveness of our optimisation strategies on triangulations of manifolds, we consider 5 specific objective functions. These objective functions are all considered on single vertex triangulations of $S^3$, call the set of all of these $\mathcal{T}_1(S^3)$.

\subsection{Alexander Polynomial}
For any $T\in\mathcal{T}_1(S^3)$, we can consider an edge $e_\alpha$, because the triangulation has only one vertex, $e_\alpha$ forms a loop. This loop can be knotted in $S^3$. Call the associated knot for $e_\alpha$ $K_\alpha$. The Alexander polynomial $\Delta_{K_\alpha}(t)$ has coefficient vector $\vec{a}=[a_0,a_1,...,a_n]$. It is known that ``more complex'' Alexander polynomials lead to ``more complex'' knots. This notion suggests 3 objective functions of interest.

\begin{enumerate}
    \item $\mathcal{O}_{deg}:T\mapsto\sum_{e_\alpha} \deg(\Delta_{K_\alpha}(t))$ where because the Alexander polynomial is invariant under multiplication by $\pm t$ we use the difference between the highest and lowest power of $t$.
    \item $\mathcal{O}_{det}:T\mapsto\sum_{e_\alpha} |\Delta_{K_\alpha}(-1)|$.
    \item $\mathcal{O}_{norm}:T\mapsto\sum_{e_\alpha} \|\vec{a}\|^2$ where $\vec{a}$ is the coefficient vector of the Alexander polynomial associated with the knot formed by the edge $e_\alpha$ in $S^3$
\end{enumerate}
The first of these objective functions, $\mathcal{O}_{deg}$ is motivated by the fact that $2g(K)\geq \deg(\Delta_K(t))$. The second objective function, $\mathcal{O}_{det}$ is motivated by the connection between the determinant $|\Delta_K(-1)|$ and the knot colouring. The third objective function, $\mathcal{O}_{norm}$ is a standard objective function on vectors.

\subsection{Fundamental Group of $T\backslash\nu( e_\alpha)$}
As discussed, for $T\in\mathcal{T}_1(S^3)$, any edge $e_\alpha$ can form a knot. Typically in knot theory we are interested in the study of the knot complement $M_\alpha=S^3\backslash \nu(K_\alpha)$. This inspires our fourth objective function
\begin{enumerate}[resume]
    \item $\mathcal{O}_{gen}:T\mapsto\sum_{e_\alpha} \#_{gen}(\pi_1(M_\alpha))$ where $\#_{gen}$ is the number of generators of the presentation of the fundamental group.
\end{enumerate}
While we would ideally like to use the reduced presentation of the fundamental group, as discussed in \ref{thm:trivial-presentation-undecidable} there is no algorithm to do this always in finite time, so we use the standard presentation returned by regina \cite{Regina}, as a heuristic, and then a reduction process can be attempted afterwards to check if the fundamental group can be reduced, and if so what it can be reduced to.

\subsection{Edge Degree Variance}
The prior four objective functions are all inspired by the knot structure of our triangulations. While this is of particular interest because it is a topological property of the triangulation, we would also like to consider the complexity of the triangulation itself. This inspires us to consider the degree of the edges in our manifold, where the degree of an edge is the number of tetrahedra that share this edge.
\begin{enumerate}[resume]
    \item $\mathcal{O}_{var}:T\mapsto \operatorname{Var}_{e_\alpha}(\deg(e_\alpha))$ where we have taken the variance.
\end{enumerate}
The choice of variance here follows from the simple argument that $V=1$ because we have defined our space of triangulations to be single vertex triangulations. We know that $\chi=0$ for $S^3$, so $1-E+F-T=0$. Also we know that each of the tetrahedra have $4$ faces, but because $S^3$ is closed they have to be glued together in pairs, so $F=2T$, this means $E=1+T$. Also, each tetrahedra has to contain $6$ edges, so the total edge degree must be $6T$, and the average edge degree $\frac{6T}{T+1}$, hence this is constant for a fixed number of tetrahedra, regardless of the triangulation. Hence the variance is chosen because it captures how ``uniform'' or conversely ``irregular'' the triangulation is.

\section{Markov Chain Monte Carlo}\label{sec:mcmc}
To establish a baseline for our objective functions, generic Markov Chain Monte Carlo was run to determine the distribution of our objective function across the Pachner Graph. The MCMC algorithm described by Altmann and Spreer \cite{Altmann2025} samples uniformly around triangulations of a particular number of tetrahedra. We, choose to examine the Pachner graph around triangulations of 30-tetrahedra, which corresponds approximately to $\gamma=1/10$. This choice is informed by other results in computational topology that have found interesting triangulations of size less than $30$ tetrahedra (for example Burton \cite{Burton2023}), and because $30$ tetrahedra is intractable to enumerate exhaustively. Samples with $7$ chains of $10,000$ iterations with a step size of $100$ where performed, for each sample all objective functions were calculated (as opposed to running distinct sampling processes for each objective function). This has the benefit of not only saving computational time, but giving us a uniform sample of the space where we can asses the correlation of each objective function. We confirmed convergence with the Gelman-Rubin statistic with a threshold of $1.01$, this threshold is in accordance with modern recommendations \cite{Vehtari2021}. The convergence statistics are in table~\ref{tab:mcmc-convergence}. For interest, figure~\ref{fig:obj-correlation} shows the correlation between each objective functions across the entire set of MCMC samples. It is important to note that this correlation tells us the correlation for ``an average'' sample, and the correlation between the functions could dramatically change in very specific parts of the distribution - in particular near the respective maxima of each variable.

We extracted the triangulations with $30$ tetrahedra, there were $8,250$ such triangulations so an efficiency of $\approx 12\%$. The following analyses are performed on this subset of triangulations.

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|}
        \hline
        Metric & $\hat{R}$ \\
        \hline
        $\mathcal{O}_{norm}$ & 1.003 \\
        $\mathcal{O}_{deg}$ & 1.004 \\
        $\mathcal{O}_{det}$ & 1.005 \\
        $\mathcal{O}_{var}$ & 1.006 \\
        $\mathcal{O}_{gen}$ & 1.009 \\
        \hline
    \end{tabular}
    \caption{Convergence statistics of MCMC Runs}
    \label{tab:mcmc-convergence}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\linewidth]{thesis/figures/obj_correlation.pdf}
    \caption{Correlation plot for each objective function.}
    \label{fig:obj-correlation}
\end{figure}

The distribution for the score for each objective function outlined in section~\ref{sec:objective-functions} is displayed in figure~\ref{fig:mcmc-score-dist}.

All but $\mathcal{O}_{var}$ present power law distributions or power law distributed tails. To confirm this we fit both a power law distribution across the entire data, and also compute $x_{\min}$ according to the procedure of Clauset, Shalizi, and Newman, and fit a power law distribution to the tails. Both these fits are done with MLE. A plot on a log-log histogram of the data, and the fitted distributions is seen in figure~\ref{fig:mcmc-score-dist-log}.

The $\mathcal{O}_{var}$ appears to have some positively skewed distribution, considering that it is the distribution of the variance, a chi squared distribution would be expected. However, fitting one to the data lead to poor results and a log normal distribution was used instead. This is weakly justified, asside from a strong in sample fit as seen in figure~\ref{fig:mcmc-var-score-dist-log} that is plotted in log-log space to confirm tail behaviour.

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{thesis/figures/agg_score_alex_deg_hist.pdf}
        \caption{$\mathcal{O}_{deg}$}
        \label{fig:mcmc-score-dist-deg}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{thesis/figures/agg_score_alex_det_hist.pdf}
        \caption{$\mathcal{O}_{det}$}
        \label{fig:mcmc-score-dist-det}
    \end{subfigure}

    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{thesis/figures/agg_score_alex_norm_hist.pdf}
        \caption{$\mathcal{O}_{norm}$}
        \label{fig:mcmc-score-dist-norm}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{thesis/figures/agg_score_num_gen_hist.pdf}
        \caption{$\mathcal{O}_{gen}$}
        \label{fig:mcmc-score-dist-gen}
    \end{subfigure}

    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{thesis/figures/agg_score_edge_var_hist.pdf}
        \caption{$\mathcal{O}_{var}$}
        \label{fig:mcmc-score-dist-var}
    \end{subfigure}

    \caption{Distribution of the score for each objective function under MCMC samples at $\gamma=1/10$}
    \label{fig:mcmc-score-dist}
\end{figure}

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{thesis/figures/agg_score_alex_deg_log_distribution.pdf}
        \caption{$\mathcal{O}_{deg}$}
        \label{fig:mcmc-score-dist-log-deg}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{thesis/figures/agg_score_alex_det_log_distribution.pdf}
        \caption{$\mathcal{O}_{det}$}
        \label{fig:mcmc-score-dist-log-det}
    \end{subfigure}

    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{thesis/figures/agg_score_alex_norm_log_distribution.pdf}
        \caption{$\mathcal{O}_{norm}$}
        \label{fig:mcmc-score-dist-log-norm}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{thesis/figures/agg_score_num_gen_log_distribution.pdf}
        \caption{$\mathcal{O}_{gen}$}
        \label{fig:mcmc-score-dist-log-gen}
    \end{subfigure}

    \caption{Log-log histogram of the score for each objective function under MCMC samples at $\gamma=1/10$. The red line indicates the fitted power law distribution over the entire dataset, the orange line the fitted power law distribution for $x>x_{\min}$}
    \label{fig:mcmc-score-dist-log}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\linewidth]{thesis/figures/agg_score_edge_var_log_distribution.pdf}
    \caption{Log-log histogram of $\mathcal{O}_{var}$ with fitted log normal distribution.}
    \label{fig:mcmc-var-score-dist-log}
\end{figure}

\section{Classical Optimisation}
\subsection{Direct Ascent}
We perform direct accent as described in section~\ref{sec:direct-accent} starting from the seed triangulation of \verb`cMcabbgqs` which has one vertex and two tetrahedra. We performed this direct accent 20 times at different temperatures ($\beta = 1/T = 0.1, \sqrt{0.1}$, $1$, $\sqrt{10}$, $10$) and compared the maximum achieved score at each level, an example of this for $\mathcal{O}_{deg}$ in figure~\ref{fig:direct-ascent-temp}. In all cases it was found that a lower temperature lead to better results, this suggests that the graph is connected enough that greedy ascent is sufficient (that is, the neighbour with the greatest score is accepted at each step).

We perform greedy ascent for each objective function for $28$ steps to a triangulation of $30$ tetrahedra, the chains are presented in figure~\ref{fig:direct-ascent-all}.

We see that for each objective function the ascent profile is almost fully deterministic. All objective functions demonstrate monotonic growth. $\mathcal{O}_{deg}$ demonstrates accelerated growth, and $\mathcal{O}_{det}$, $\mathcal{O}_{var}$, and $\mathcal{O}_{norm}$ demonstrate linear growth; in either case this suggests that an arbitrarily high score can be achieved by simply extending this procedure to larger triangulations. On the other hand, $\mathcal{O}_{gen}$ appears to be plateauing suggesting that the exploration technique may not yield significant improvement as we extend to large triangulations. Interestingly, $\mathcal{O}_{var}$ presenting slightly better than expected values for even triangulations than odd triangulations (if we assume linearity), this leads to a slight oscillating behaviour.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{thesis/figures/direct_ascent_temp.pdf}
    \caption{Direct Ascent on $\mathcal{O}_{deg}$ at different temperatures ($\beta=1/T$)}
    \label{fig:direct-ascent-temp}
\end{figure}

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{thesis/figures/direct_ascent_all_deg.pdf}
        \caption{$\mathcal{O}_{deg}$}
        \label{fig:direct-ascent-all-deg}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{thesis/figures/direct_ascent_all_det.pdf}
        \caption{$\mathcal{O}_{det}$}
        \label{fig:direct-ascent-all-det}
    \end{subfigure}

    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{thesis/figures/direct_ascent_all_norm.pdf}
        \caption{$\mathcal{O}_{norm}$}
        \label{fig:direct-ascent-all-norm}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{thesis/figures/direct_ascent_all_gen.pdf}
        \caption{$\mathcal{O}_{gen}$}
        \label{fig:direct-ascent-all-gen}
    \end{subfigure}

    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{thesis/figures/direct_ascent_all_var.pdf}
        \caption{$\mathcal{O}_{var}$}
        \label{fig:direct-ascent-all-var}
    \end{subfigure}

    \caption{Direct / greedy ascent for each objective function.}
    \label{fig:direct-ascent-all}
\end{figure}

While the direct ascent approach does appear to perform particularly well and predictably, and is an incredibly simple algorithm to implement. It only generates a single triangulation, and requires calculating the objective function on a large number of discarded triangulations - in total to generate the ascent profile of 28 triangulations required exploring on the order of $1,000$ triangulations. As such, in situations where a single high value triangulation is desired, this technique demonstrates value. However, if the goal is to explore a variety of different high valued triangulations and have a high exploration efficiency - this technique is not suitable.

\subsection{Simulated Annealing}
We perform simulated annealing as described in section~\ref{sec:simulated-annealing}. This is done for a target of $10,000$ iterations with a step size of $10$ and target acceptance rate of $20\%$, $\alpha=0.01$ and $\lambda=0.1$, this acceptance rate was chosen heuristically based on a number of different small experiments. To ensure a fair comparison with direct ascent, the potential was set to $-\infty$ for triangulations with more than 30 tetrahedra. For $\mathcal{O}_{deg}$ and $\mathcal{O}_{norm}$, the chain was stopped early at $3,307$ and $2,940$ samples because the computational time required to score a single triangulation had become unfeasibly slow ($>10$second$/$sample). The actual acceptance rate was calculated in each case. For $\mathcal{O}_{det}, \mathcal{O}_{gen}$ and $\mathcal{O}_{var}$ the achieved acceptance rate was within $1\%$ of the target. For $\mathcal{O}_{deg}$ and $\mathcal{O}_{norm}$ the acceptance rate is lower, though this is likely due to the reduced number of samples achieved. The chains for each objective function and the achieved acceptance rates are included in figure~\ref{fig:simulated-annealing}.

For $\mathcal{O}_{deg}$ and $\mathcal{O}_{norm}$ which were both stopped early, the objective function appears to still be increasing, suggesting that a higher objective function could have been achieved if let run for the full 10,000 iterations. However, it is important to realise that the more complex a knot is, the longer it takes to calculate the Alexander polynomial, so if the algorithm was to continue to run and improve the objective function, it is likely that it would continue to slow down. The computation for the Alexander polynomial is slow because the symbolic determinant of a large collection of matrices is required to be calculated. This is a poorly optimised problem. However, the full symbolic result is possibly not required, and specific algorithms to calculate the degree and norm could potentially be developed to significantly improve the compute time, and leverage the parallelism of GPUs. $\mathcal{O}_{gen}$, and $\mathcal{O}_{var}$ both appeared to plateau relatively early and did not show significant improvement after around $2,000$ epochs. Similar could be suggested for $\mathcal{O}_{det}$, though the results are less conclusive.

\begin{figure}
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{thesis/figures/sim_annealing_deg.pdf}
        \caption{$\mathcal{O}_{deg}$ acceptance rate: $17.78\%$}
        \label{fig:simulated-annealing-deg}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{thesis/figures/sim_annealing_det.pdf}
        \caption{$\mathcal{O}_{det}$ acceptance rate: $19.96\%$}
        \label{fig:simulated-annealing-det}
    \end{subfigure}

    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{thesis/figures/sim_annealing_norm.pdf}
        \caption{$\mathcal{O}_{norm}$ acceptance rate: $18.44\%$}
        \label{fig:simulated-annealing-norm}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{thesis/figures/sim_annealing_gen.pdf}
        \caption{$\mathcal{O}_{gen}$ acceptance rate: $20.11\%$}
        \label{fig:simulated-annealing-gen}
    \end{subfigure}

    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{thesis/figures/sim_annealing_var.pdf}
        \caption{$\mathcal{O}_{var}$ acceptance rate: $19.44\%$}
        \label{fig:simulated-annealing-var}
    \end{subfigure}

    \caption{Trace plots for simulated annealing on each objective function for 10,000 iterations and a $20\%$ acceptance rate.}
    \label{fig:simulated-annealing}
\end{figure}

\section{Comparison of Classical Optimisation}
The best result from each optimisation technique are compiled in table~\ref{tab:classical-results}. This table includes the achieved percentile of the best sample, computed by the fitted power law distribution for both the entire distribution (overall) and the tail distribution (tail) from section~\ref{sec:mcmc}.

In all cases the search techniques uncovered samples that where at least in the $10^{-5}$th percentile. Meaning that $100,000$ samples of $30$ tetrahedra would be required. Given the $30$ tetrahedra sampling rate was on the order of $10\%$ at least $1,000,000$ samples from MCMC would be required to find a solution as good, simulated annealing only used $10,000$, and direct ascent only around $1,000$ making the classical search techniques at least $100\times$ more efficient. In the best case scenario, the score was in the $10^{-13}$th percentile (conservatively choosing the largest of total and tail) making the search at least $10^{10}\times$ more efficient.

With the exception of $\mathcal{O}_{det}$, the simulated annealing performed better than the greedy ascent. That being said, simulated annealing also had to perform $2\times$ to $5\times$ more calculations than the direct ascent (of the $10,000$ steps, the model would sometimes propose an already visited node which didn't need to be recomputed). The improvement was 1-2 orders of magnitude in percentile (conservatively) suggesting that simulated annealing is the better choice when maximising the objective function as much as possible is desired. Though the increased complexity in the algorithm, and the slower $2\times$ to $5\times$ slower runtime are drawbacks if absolute maximums are not required. Interestingly, $\mathcal{O}_{det}$ performed significantly better under direct ascent. Achieving a particularly high percentile on the order $10^{-13}$. It was not entirely clear that simulated annealing for $\mathcal{O}_{det}$ had settled down, and a longer chain may have achieved better results, but it is also possible that the objective function for $\mathcal{O}_{det}$ is convex enough that direct ascent is highly efficient.

For the knot based objective functions, we consider the best triangulations achieved overall from both techniques, identifying which edge within the triangle has the most complex knot (as defined by the objective function).

For $\mathcal{O}_{deg}$ the edge that had the greatest degree had a degree of $1,626$. Additionally, it had a fundamental group that was not of the form $\langle a, b\;|\; a^pb^{-q}\rangle$ and had an Alexander polynomial that could not be decomposed over $\mathbb{Q}$, as such it is not a torus knot, and is likely a prime knot. It could be a satellite knot.

For $\mathcal{O}_{det}$ the edge that had the greatest determinant had a determinant of $57$. The Alexander polynomial factors to $(a^4 - a^3 + a^2 - a + 1) (a^{20} - a^{15} + a^{10} - a^5 + 1)$ and the fundamental group was $\langle a b \;|\; a^{12} b a^{-13} b \rangle$. This could be a $(5,2)-$cable of the $(5,2)-$torus knot. In total for this triangulation, $3$ of the edges where unknots.

For $\mathcal{O}_{norm}$ the edge that had the greatest norm had a norm of $359$. The Alexander polynomial had degree $724$ and fundamental group with three generators. The Alexander polynomial has alternating $+1, -1$ coefficients suggesting a torus knot (the fundamental group may not be simplified)
In total for this triangulation, $3$ of the edges where unknots.

For $\mathcal{O}_{gen}$ the edge that had the greatest number of generators had a $51$ generators, but after simplification only had $3$. The Alexander polynomial had degree $162$. The Alexander polynomial has alternating $+1, -1$ coefficients suggesting a torus knot (the fundamental group may not be fully simplified)
In total for this triangulation, $4$ of the edges where unknots.

For $\mathcal{O}_{var}$ the best triangulation had edges primarily with degree $1, 2$ or $3$ and with one edge of degree $131$. For this triangulation, all edges where unknotted.

\begin{landscape}
\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|c|}
        \hline
        Objective Function & \multicolumn{3}{|c|}{Direct Ascent} & \multicolumn{3}{|c|}{Simulated Annealing} \\
        \hline
         & Score & Total Percentile & Tail Percentile & Score & Total Percentile & Tail Percentile \\
        \hline
        $\mathcal{O}_{deg}$ & $152.26$ & $7.19\cdot 10^{-05}$ & $1.21\cdot 10^{-05}$ & $433.42$ & $2.12\cdot 10^{-05}$ & $2.66\cdot 10^{-06}$ \\
        $\mathcal{O}_{det}$ & $27.19$ & $1.38\cdot 10^{-13}$ & $2.62\cdot 10^{-13}$ & $13.84$ & $5.86\cdot 10^{-11}$ & $1.61\cdot 10^{-10}$ \\
        $\mathcal{O}_{norm}$ & $29.06$ & $7.16\cdot 10^{-12}$ & $3.29\cdot 10^{-06}$ & $152.26$ & $2.38\cdot 10^{-17}$ & $1.23\cdot 10^{-08}$ \\
        $\mathcal{O}_{gen}$ & $1.94$ & $1.58\cdot 10^{-06}$ & $2.32\cdot 10^{-05}$ & $2.65$ & $2.93\cdot 10^{-09}$ & $1.14\cdot 10^{-07}$ \\
        $\mathcal{O}_{var}$ & $412.54$ & $3.06\cdot10^{-15}$ &  & $522.93$ & $7.52\cdot 10^{-18}$ & \\
        \hline
    \end{tabular}
    \caption{Comparison of maximum achieved objective function for both classical sampling techniques. Percentiles of each score based on bulk and tail fitted power law distributions.}
    \label{tab:classical-results}
\end{table}

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|}
        \hline
         & Best Triangulation (\verb|IsoSig|) \\
        \hline
        $\mathcal{O}_{deg}$ & \verb|EMzMzMzMzMvAAMzMzMzMPabcdefghijklmnqpqrstuvwxyzABCDDjxxxxxxxxxxxxxlfxfxxxxxxxxxxxxj| \\
        $\mathcal{O}_{det}$ & \verb|ELLMMzMzMzMzMzMzMzMzQbeddfghijklmnopqrstuvwxyzABCDDDxxrfaxxxxxxxxxxxxxxxxxxxxxxxxvc| \\
        $\mathcal{O}_{norm}$ & \verb|EMzMzMzMzMvAAMzMzMzMPabcdefghijklmnqpqrstuvwxyzABCDDjxxxxxxxxxxxxxlfxfxxxxxxxxxxxxj| \\
        $\mathcal{O}_{gen}$ & \verb|ELwvMvQPLMzAPLLAPMzPQcbehgklimllpnqptrutwvzxyABDCBDDaacmvlpvlooashoqkmbuoageahamkcg| \\
        $\mathcal{O}_{var}$ & \verb|EMzMzMzMzMzMvAAMzMzMPabcdefghijklmnopqsttuvwxyzABCDDvaaaaaaaaaaaaaaaaciqnaaaaaaaaav| \\
        \hline
    \end{tabular}
    \caption{Best Triangulation Direct Ascent}
    \label{tab:t-best-dirct}
\end{table}

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|}
        \hline
         & Best Triangulation (\verb|IsoSig|) \\
        \hline
        $\mathcal{O}_{deg}$ & \verb|ELvLLzvMvzMQAMLMQzQMQbdgfjpmtosmvruqptvwuzyxBCzACBDDafgfjxaovwrdsifjouitrwblqjfhroj| \\
        $\mathcal{O}_{det}$ & \verb|ELLvMLAAzPwMzAPzvAMQQadeihhhljnplnqpturttxBBCADBAADDbabagjgxbadjbhohagkfauahoxrccjo| \\
        $\mathcal{O}_{norm}$ & \verb|EvLPzvvzLAvzLPPQQMQQQdcdgklqsvoAptytAzBxxzCwyBBDzADDonnapdeaacqowdbauqadasckkjabvhd| \\
        $\mathcal{O}_{gen}$ & \verb|ELMvLAAvMAQzLwPLAMMMPcbdgfiihnmloopnqtsvtxwyzyABACDDaaaavlsvaccfbxsaqranmglanxxnxxr| \\
        $\mathcal{O}_{var}$ & \verb|EMLLLvzPPzwPLMQzAPzAQabddglnjokkqnouqswstuvwzyzBCDCDgagbaaagacvaggaccavgfbcafcoaaco| \\
        \hline
    \end{tabular}
    \caption{Best Triangulation Simulated Annealing}
    \label{tab:t-best-sa}
\end{table}
\end{landscape}

\section{Baseline Transformer Efficiency on Isomorphism Signatures}
A dataset of triangulations of $S^3$ is collected for a range of different sizes ($6-$tetrahedra to $12-$tetrahedra). These either come from the census of triangulations \cite{Regina}, or from MCMC. A separate transformer model is trained for each number of tetrahedra. Each transformer has the exact same parameters: an embedding dimension of $64$, $6$ layers, $8$ heads, a dropout rate of $0.1$, and a learning rate of $0.0005$. Each model was trained from the same starting key for $50,000$ iterations, where an iteration is a single batch of size $32$. Each batch was a randomised sample from the training data. A fixed, random, test set of $1,000$ was used for validation. These parameters were chosen as a computationally reasonable starting point for training, though there is significant research to suggest that larger models will perform better, especially given the essentially unlimited training data that we have \cite{Kaplan2020}.

Figure~\ref{fig:sgd-test-losses} shows a log-log plot of the test loss over the number of iterations. It is evident that the curves are still decreasing, and at $50,000$ iterations there isn't significant enough curvature to infer when the training would plateau, this suggests that further training time would yield better results. Regardless of the small architecture and low training time, the data does exhibit promising results.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{thesis/figures/sgd_test_losses.pdf}
    \caption{Caption}
    \label{fig:sgd-test-losses}
\end{figure}

 Figure~\ref{fig:generation-efficiency} and table~\ref{tab:generation-efficiency} show the generation efficiency for the transformers trained on different numbers of tetrahedra. ``Loads'' indicates if the whether the generated string is formatted correctly to be loaded into regina. ``Valid'' checks if the string represents a topologically valid triangulation, i.e. doesn't have any singularities etc. in it. ``Closed'' checks if the manifold is closed (compact and has no boundary). ``Sphere'' checks if the manifold represents a sphere, i.e. if its fundamental group is trivial. In general, of the manifolds that load, almost all of them are valid. Also, of the manifolds that are closed about $70\%$ are spheres - though there is not enough data to suggest if this holds true in general. However, the fraction of valid manifolds that are closed does show evidence that it is decreasing as the number of tetrahedra increases.

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|c|}
        \hline
        \# Tetrahedra & Loads & Valid & Closed & Sphere \\
        \hline
        $6$ & $0.195$ & $0.195$ & $0.115$ & $0.086$ \\
        $7$ & $0.08$ & $0.08$ & $0.039$ & $0.0235$ \\
        $8$ & $0.043$ & $0.0425$ & $0.02$ & $0.0115$ \\
        $9$ & $0.0185$ & $0.0185$ & $0.004$ & $0.004$ \\
        $10$ & $0.008$ & $0.008$ & $0.0025$ & $0.001$ \\
        $11$ & $0.0075$ & $0.0075$ & $<0.001$ & $<0.001$ \\
        $12$ & $0.001$ & $<0.001$ & $<0.001$ & $<0.001$ \\
        \hline
    \end{tabular}
    \caption{Generation efficiency at different number of tetrahedra.}
    \label{tab:generation-efficiency}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{thesis/figures/generation_efficiency.pdf}
    \caption{Caption}
    \label{fig:generation-efficiency}
\end{figure}


\chapter{Discussion and Conclusion}
% \section{Discussion}
% \subsection{Guided Search}



% \section{Future Work}
% \subsection{Reinforcement Learning}
% We have successfully trained transformers to be able to generate triangulations, though the efficiency isn't particularly high. Before deciding to do reinforcement learning on the objective function, it may be beneficial to improve the rate at which the model is generating valid spheres. Apart from increasing the amount of training time, one possible avenue would be to do reinforcement learning with the objective being whether or not the triangulation is a sphere (or to start simply if its valid). In order to apply reinforcement learning, it is generally required that the number of positive samples per batch is $\geq1$. Considering our batch size is $32$, this would mean the efficiency needs to be above $0.03$. This is achieved for $6-$tetrahedra directly for spheres, and for $6, 7, 8-$tetrahedra for the initial task of being valid. The batch size could certainly be increased though this would require more compute power. As such, reinforcement learning is a valid avenue immediately for triangulations of size $6, 7$ and $8$, and would likely apply to larger triangulations after training with gradient descent for longer and with a larger model.

% \subsection{Alternate Isomorphism Signatures}
% It is a well empirically observed result that increasing the embedding dimension increases performance for transformers. This can be explained with two factors. Firstly, in general more parameters of any form gives the model more freedom and nuance allowing it to fit to the data better. Secondly, and more pertinent, the embedding layer is the component of the model that learns to express what each letter ``means''. With the current isomorphism signatures, they are simply representations of numbers, so specific letters don't contain any geometric meaningful information, the model has to ``waste effort'' learning how to decode the isomorphism signatures, which is a relatively sophisticated encoding structure. A different encoding strategy could be used to represent the triangulations where each token has a specific and unique meaning. One possibility is ``dehydrated isomorphism signatures''. These have a potential advantage because each pair of letters encodes a unique piece of geometric information, and the position encodes the gluing information. This is far more subtile for the specific task that transformers were developed to handle and using such a signature could lead to faster training times, and higher accuracy for the same sized model. Additionally, there could be potential interest in the embedding vectors learned themselves.

% \subsection{Alternative Architectures}

\section{Discussion}
% Paragraph 1: Summarise the primary success of the classical methods.
This study examines single vertex triangulations of the three sphere. We successfully implement and compare classical heuristic search algorithms against a baseline established with MCMC. The primary result of our analysis is that classical heuristics are able to find exceptional triangulations, often with knot theoretic properties falling with the $10^{-10}$th percentile or rarer compared to the baseline distribution. In general we find that simulated annealing approaches work better than greedy ascent, suggesting that in order to navigate the Pachner graph efficiently, a degree of randomness is needed, indicating that the landscape has non-convex structure with local optima / locally optimal paths.

% Paragraph 2: Integrate your point about the limitations of the objective functions.
While the optimisation techniques are powerful, their success is intrinsically linked to the objective function chosen. During the development of the optimisation techniques, there was interest in understanding if guided search could be used to discover specific, special types of triangulations. In particular, we were interested to see if we could use guided search to discover a triangulation where all the edges were knotted. Burton had used targeted search to find an example where this was true. The concept was that if we find a triangulation which exhibits particularly high ``knottedness'' in general, it may be more likely to have all of its edges knotted. However, after running optimisation on a range of different objective functions, we found that we could achieve much higher values for the objective functions than what was actually obtained by the triangulation discovered by Burton. That is, the objective functions did not discriminate enough to be used to locate such a triangulation. This is not a failure in the optimisation techniques, but rather in the definition of the objective function. In general, if the discussed optimisation techniques are to be used for searching for specific triangulations, it needs to be done on some objective function that is known to be optimised by a hypothetical solution. For example - the number of edges unknotted is known to be minimised by a triangulation of the desired form (tautologically), unfortunately it is too flat to actually serve any value for searching (tending to ``hover'' around 2).

The main current main limitations of the presented search techniques are twofold. Firstly, they are local search techniques. They generate chains of samples that are all quite similar leading to extended periods of sampling triangulations that all have similar objective functions, thereby wasting compute not gaining any significant new information. We do lay the groundwork for deep learning based approaches that may combat this issue, but further work needs to be done to determine if they are viable. Secondly, the objective functions used become increasingly computationally intensive as the solutions we are examining become more optimal. This is somewhat unavoidable, but there is possible wasted compute determining the full polynomial Alexander polynomial, for it to later be reduced to a single number. This could potentially be saved and open the door for the computation to become ``embarrassingly parallel'', lending itself to modern GPU hardware.

% Paragraph 3: Discuss the transformer experiments as a proof-of-concept and its current limitations.
To address the sequential limitation of the classical search techniques, we investigated generative machine learning techniques, namely autoregressive transformers trained on the isomorphism signatures of the triangulations. We have demonstrated initial proof of concepts with these models on small triangulations, but find diminishing success with larger triangulations. This diminishing success is expected, and there is evidence that the accuracy can simply be improved with longer training times. The need for increased training times is a bottle neck for developing models to generate large / complex triangulations. In particular, to open up the avenue for reinforcement learning we need to push the initial accuracy above some minimum threshold, which is currently only being exhibited on small triangulations.

\section{Conclusion}
This report has provided a range of approaches to navigating the Pachner graph. We have successfully demonstrated that classical search heuristics dominate uniform random sampling for uncovering particularly exceptional triangulations with complex knot structures. The methods provide a practical and objective function agnostic approach to exploring the Pachner graph that may be implemented easily. Further, we have laid the groundwork to open the door to deep learning, successfully demonstrating a proof of concept generative transformer that can successfully generate triangulations. While there are still challenges with the efficiency of the generative techniques, there is evidence that the efficiency can be improved to the level required for reinforcement learning - a technique that we believe has the opportunity for great success.

\section{Future Work}
The results and limitations discussed above suggest a range of possible avenues to move forward, primarily around improving the generative model and applying reinforcement learning. Particularly to see if it outperforms simulated annealing.

\subsection{Advancing the Generative Model}
The immediate priority should be to improve the generative efficiency of the model. There are two avenues forward for this.

Firstly, reinforcement learning can be used to improve the generative efficiency. That is, we can use it as a fine tuning techniques to encourage the generation of valid, closed, or spherical triangulations. As the results have demonstrated, for small triangulations of $6-8$ tetrahedra, this technique could already be directly applied as the generative efficiency is already in the $2-3\%$ range required for to get positive reward signals in a batch size of $32$.

Secondly, it is a well empirically observed result that increasing the embedding dimension increases performance for transformers. This can be explained with two factors. Firstly, in general more parameters of any form gives the model more freedom and nuance allowing it to fit to the data better. Secondly, and more pertinent, the embedding layer is the component of the model that learns to express what each letter ``means''. With the current isomorphism signatures, they are simply representations of numbers, so specific letters don't contain any geometric meaningful information, the model has to ``waste effort'' learning how to decode the isomorphism signatures, which is a relatively sophisticated encoding structure. A different encoding strategy could be used to represent the triangulations where each token has a specific and unique meaning. One possibility is ``dehydrated isomorphism signatures''. These have a potential advantage because each pair of letters encodes a unique piece of geometric information, and the position encodes the gluing information. This is far more subtile for the specific task that transformers were developed to handle and using such a signature could lead to faster training times, and higher accuracy for the same sized model. Additionally, there could be potential interest in the embedding vectors learned themselves.

\subsection{Alternative Architectures}
If changing the representation of the isomorphism signature, and increasing computational time is found to be insufficient, there are alternative avenues forwards with the actual neural network architecture.

Firstly, trying to generate the isomorphism signature letter by letter is a highly fragile procedure, at each step there may be a probability of making a mistake and generating a single invalid character, after doing this repeatedly the chance of making a single mistake which would invalidate the entire isomorphism signature compounds. And once a mistake is made there is no ``going back''. This suggests the possibility of training diffusion style models, these can be trained to require less steps to generate a result, and can also be designed to be able to correct errors that have been made, based on the context of the entire string. This error correcting ability is potentially of significant value for improving efficiency.

Secondly, a triangulation is fundamentally a graph type structure, using graph aware or graph neural networks may be a better choice for the data than sequential style models. A graph style model could be more suited to quickly uncovering the underlying structure and rules of a valid triangulation, meaning smaller networks could be trained faster to achieve equivalent efficiencies.

\subsection{Reinforcement Learning for Topological Optimisation}
The main next steps once generation efficiency has been improved, is to perform reinforcement learning to improve the topological objective function outlined above, and compare them to the results of the classical optimisation. The improved generative model would be trained with the objective functions explored in this report as reward signals. Using algorithms such as proximal policy optimisation (PPO), the model could directly be trained to generate novel triangulations that maximise knot theoretic or combinatorial properties. This could be a powerful new approach to the problem that involves models that can actually encode the geometry, as opposed to heuristic search algorithms.

\bibliographystyle{plain}
\bibliography{references}

\end{document}
